{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data\n",
    "\n",
    "This notebook parses some of the CARDiPS files to take only data that we need for this project. \n",
    "This notebook will only run on the Frazer lab cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/frazer01/home/cdeboever/software/anaconda/envs/cie/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import cdpybio as cpb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import ciepy\n",
    "import cardipspy as cpy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outdir = os.path.join(ciepy.root, 'output',\n",
    "                      'input_data')\n",
    "cpy.makedir(outdir)\n",
    "\n",
    "private_outdir = os.path.join(ciepy.root, 'private_output',\n",
    "                              'input_data')\n",
    "cpy.makedir(private_outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dy = '/projects/CARDIPS/data/database/20151201'\n",
    "\n",
    "fn = os.path.join(dy, 'baseline_analyte.tsv')\n",
    "baseline_analyte = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'baseline_wgsisaac.tsv')\n",
    "baseline_wgsisaac = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'baseline_ipsc.tsv')\n",
    "baseline_ipsc = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'baseline_wgs.tsv')\n",
    "baseline_wgs = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'baseline_cnv.tsv')\n",
    "baseline_cnv = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'baseline_rnas.tsv')\n",
    "baseline_rnas = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'baseline_ibd.tsv')\n",
    "baseline_ibd = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'baseline_manifest.tsv')\n",
    "baseline_manifest = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'baseline_snpa.tsv')\n",
    "baseline_snpa = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'baseline_tissue.tsv')\n",
    "baseline_tissue = pd.read_table(fn, index_col=0)\n",
    "\n",
    "fn = os.path.join(dy, 'family1070_rnas.tsv')\n",
    "family1070_rnas = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'family1070_tissue.tsv')\n",
    "family1070_tissue = pd.read_table(fn, index_col=0)\n",
    "\n",
    "fn = os.path.join(dy, 'subject_pedigree.tsv')\n",
    "subject_pedigree = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'subject_family.tsv')\n",
    "subject_family = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'subject_subject.tsv')\n",
    "subject_subject = pd.read_table(fn, index_col=0)\n",
    "\n",
    "#fn = os.path.join(dy, 'data_wgs.tsv')\n",
    "#data_wgs = pd.read_table(fn, index_col=0)\n",
    "#fn = os.path.join(dy, 'data_snpa.tsv')\n",
    "#data_snpa = pd.read_table(fn, index_col=0)\n",
    "#fn = os.path.join(dy, 'data_array.tsv')\n",
    "#data_array = pd.read_table(fn, index_col=0)\n",
    "#fn = os.path.join(dy, 'data_chips.tsv')\n",
    "#data_chips = pd.read_table(fn, index_col=0)\n",
    "#fn = os.path.join(dy, 'data_atacs.tsv')\n",
    "#data_atacs = pd.read_table(fn, index_col=0)\n",
    "#fn = os.path.join(dy, 'data_metha.tsv')\n",
    "#data_metha = pd.read_table(fn, index_col=0)\n",
    "#fn = os.path.join(dy, 'data_hic.tsv')\n",
    "#data_hic = pd.read_table(fn, index_col=0)\n",
    "#fn = os.path.join(dy, 'data_rnas.tsv')\n",
    "#data_rnas = pd.read_table(fn, index_col=0)\n",
    "#fn = os.path.join(dy, 'data_sequence.tsv')\n",
    "#data_sequence = pd.read_table(fn, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dy = '/projects/CARDIPS/pipeline/RNAseq/combined_files'\n",
    "censor = pd.read_table(os.path.join(dy, 'censor.tsv'),\n",
    "                       index_col=0, header=None, squeeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array CNVs\n",
    "\n",
    "I'm going to make a table of all CNVs identified by arrays. Some iPSC didn't have\n",
    "any CNVs. For now, if an iPSC is in the CNV table, that means that it either\n",
    "didn't have CNVs or we didn't test that clone/passage number for CNVs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnv = baseline_cnv.merge(baseline_snpa, left_on='snpa_id', right_index=True,\n",
    "                         suffixes=['_cnv', '_snpa'])\n",
    "cnv = cnv.merge(baseline_analyte, left_on='analyte_id', right_index=True,\n",
    "                suffixes=['_cnv', '_analyte'])\n",
    "cnv = cnv.merge(baseline_tissue, left_on='tissue_id', right_index=True,\n",
    "                suffixes=['_cnv', '_tissue'])\n",
    "cnv = cnv[['type', 'chr', 'start', 'end', 'len', 'primary_detect_method', \n",
    "           'clone', 'passage', 'subject_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA-seq Samples for this Study\n",
    "\n",
    "I'm going to use baseline and family 1070 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get family1070 samples.\n",
    "tdf = family1070_rnas[family1070_rnas.comment.isnull()]\n",
    "tdf = tdf.merge(family1070_tissue, left_on='tissue_id', right_index=True, \n",
    "                suffixes=['_rna', '_tissue'])\n",
    "tdf = tdf[tdf.cell_type == 'iPSC']\n",
    "tdf.index = tdf.rnas_id\n",
    "tdf = tdf[['ipsc_clone_number', 'ipsc_passage', 'subject_id']]\n",
    "tdf.columns = ['clone', 'passage', 'subject_id']\n",
    "tdf['isolated_by'] = 'p'\n",
    "tdf.index.name = 'rna_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the iPSC eQTL samples.\n",
    "rna = baseline_rnas[baseline_rnas.rnas_id.isnull() == False]\n",
    "rna.index = rna.rnas_id\n",
    "rna.index.name = 'rna_id'\n",
    "# TODO: update this to use table status column eventually.\n",
    "rna = rna.ix[censor[censor == False].index]\n",
    "rna = rna.merge(baseline_analyte, left_on='analyte_id', right_index=True,\n",
    "                suffixes=['_rnas', '_analyte'])\n",
    "rna = rna.merge(baseline_tissue, left_on='tissue_id', right_index=True,\n",
    "                suffixes=['_rnas', '_tissue'])\n",
    "rna = rna[['clone', 'passage', 'subject_id']]\n",
    "rna['isolated_by'] = 'a'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: working here. I need to redo the above when the rest of the samples\n",
    "are added into baseline_rnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 subjects not in the 222 cohort.\n"
     ]
    }
   ],
   "source": [
    "# Get subjects from Roy's paper.\n",
    "cohort222 = baseline_ipsc.merge(baseline_tissue, left_on='tissue_id', \n",
    "                                right_index=True,  suffixes=['_ipsc', '_tissue'])\n",
    "n = len(set(rna.subject_id) - set(cohort222.subject_id))\n",
    "print('{} subjects not in the 222 cohort.'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary/private columns.\n",
    "rna = rna.drop(['name', 'cell', 'day', 'rep', 'status', 'comment'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm can use all of these samples that passed QC for various expression analyses.\n",
    "\n",
    "### eQTL samples\n",
    "\n",
    "Now I'm going to identify one sample per subject to use for eQTL analysis.\n",
    "\n",
    "I'll start by keeping samples whose clone/passage number matches up with \n",
    "those from the 222 cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rna['in_eqtl'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/frazer01/home/cdeboever/software/anaconda/envs/cie/lib/python2.7/site-packages/pandas/core/indexing.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/frazer01/home/cdeboever/software/anaconda/envs/cie/lib/python2.7/site-packages/pandas/core/indexing.py:426: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "samples = (cohort222.subject_id + ':' + cohort222.clone.astype(int).astype(str) + \n",
    "           ':' + cohort222.passage.astype(int).astype(str))\n",
    "\n",
    "t = rna.dropna(subset=['passage'])\n",
    "t.loc[:, ('sample')] = (t.subject_id + ':' + t.clone.astype(int).astype(str) + \n",
    "                        ':' + t.passage.astype(int).astype(str))\n",
    "t = t[t['sample'].apply(lambda x: x in samples.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These samples are in the 222 cohort and the eQTL analysis.\n",
    "rna['in_222'] = False\n",
    "rna.ix[t.index, 'in_222'] = True\n",
    "rna.ix[t.index, 'in_eqtl'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll add in any samples for which we have CNVs but weren't in the 222."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = (cnv.subject_id + ':' + cnv.clone.astype(int).astype(str) + \n",
    "           ':' + cnv.passage.astype(int).astype(str))\n",
    "\n",
    "t = rna.dropna(subset=['passage'])\n",
    "t.loc[:, ('sample')] = (t.subject_id + ':' + t.clone.astype(int).astype(str) + \n",
    "                        ':' + t.passage.astype(int).astype(str))\n",
    "t = t[t['sample'].apply(lambda x: x in samples.values)]\n",
    "t = t[t.subject_id.apply(lambda x: x not in rna.ix[rna.in_eqtl, 'subject_id'].values)]\n",
    "\n",
    "# These samples aren't in the 222 but we have a measured CNV for them.\n",
    "rna.ix[t.index, 'in_eqtl'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll add in samples where the clone was in the 222 but we don't have the same passage\n",
    "number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = (cohort222.subject_id + ':' + cohort222.clone.astype(int).astype(str))\n",
    "\n",
    "t = rna[rna.in_eqtl == False]\n",
    "t = t[t.subject_id.apply(lambda x: x not in rna.ix[rna.in_eqtl, 'subject_id'].values)]\n",
    "t['samples'] = t.subject_id + ':' + t.clone.astype(int).astype(str)\n",
    "t = t[t.samples.apply(lambda x: x in samples.values)]\n",
    "\n",
    "# These clones are in the 222, we just have a different passage number.\n",
    "rna['clone_in_222'] = False\n",
    "rna.ix[rna.in_222, 'clone_in_222'] = True\n",
    "rna.ix[t.index, 'clone_in_222'] = True\n",
    "rna.ix[t.index, 'in_eqtl'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll add in any samples from subjects we don't yet have in the eQTL analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = rna[rna.in_eqtl == False]\n",
    "t = t[t.subject_id.apply(lambda x: x not in rna.ix[rna.in_eqtl, 'subject_id'].values)]\n",
    "\n",
    "rna.ix[t.index, 'in_eqtl'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 215 distinct subjects in the eQTL analysis.\n"
     ]
    }
   ],
   "source": [
    "n = rna.in_eqtl.value_counts()[True]\n",
    "print('We have {} distinct subjects in the eQTL analysis.'.format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WGS Samples\n",
    "\n",
    "Now I'll assign WGS IDs for each RNA-seq sample. Some subjects have multiple WGS samples\n",
    "for different cell types. I'll preferentially use blood, fibroblast, and finally iPSC WGS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rna['wgs_id'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove censored samples.\n",
    "wgs = data_wgs[data_wgs.status == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No WGS: 4ebf16ec-bcdb-47f3-aefe-5e14cd1735d5\n",
      "No WGS: 2c2697a7-584f-4767-bc64-23a833648e81\n",
      "No WGS: 9809009f-63db-4a16-8fe3-a11a474f896f\n",
      "No WGS: 1c568951-4308-4270-b40a-0380bffe699c\n",
      "No WGS: c29ee90a-9cc0-4552-9f76-5d00f9ed0335\n",
      "No WGS: 629211b6-49d7-4024-879c-3ac5bc86f9d9\n",
      "No WGS: c5bc184d-3853-4cf4-92fd-bd561704154a\n",
      "No WGS: eb9cd395-ccf7-4b0c-a9cd-b48129992972\n"
     ]
    }
   ],
   "source": [
    "for i in rna.index:\n",
    "    s = rna.ix[i, 'subject_id']\n",
    "    t = wgs[wgs.subject_id == s]\n",
    "    if t.shape[0] == 1:\n",
    "        rna.ix[i, 'wgs_id'] = t.index[0]\n",
    "    elif t.shape[0] > 1:\n",
    "        if 'Blood' in t.cell.values:\n",
    "            t = t[t.cell == 'Blood']\n",
    "        elif 'iPSC' in t.cell.values:\n",
    "            t = t[t.cell == 'iPSC']\n",
    "        if t.shape[0] == 1:\n",
    "            rna.ix[i, 'wgs_id'] = t.index[0]\n",
    "        else:\n",
    "            print('?: {}'.format(i))\n",
    "    else:\n",
    "        print('No WGS: {}'.format(i))\n",
    "        rna.ix[i, 'in_eqtl'] = False\n",
    "\n",
    "rna.ix[rna['wgs_id'] == '', 'wgs_id'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 samples in eQTL analysis without WGS data.\n"
     ]
    }
   ],
   "source": [
    "n = len(set(rna[rna.in_eqtl].index) & set(rna[rna.wgs_id == ''].index))\n",
    "print('{} samples in eQTL analysis without WGS data.'.format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to keep one WGS sample per person in the cohort \n",
    "(preferentially blood, fibroblast, and finally iPSC) even if we don't\n",
    "have RNA-seq in case we want to look at phasing etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vc = wgs.subject_id.value_counts()\n",
    "vc = vc[vc > 1]\n",
    "\n",
    "keep = []\n",
    "for s in vc.index:\n",
    "    t = wgs[wgs.subject_id == s]\n",
    "    if t.shape[0] == 1:\n",
    "        keep.append(t.index[0])\n",
    "    elif t.shape[0] > 1:\n",
    "        if 'Blood' in t.cell.values:\n",
    "            t = t[t.cell == 'Blood']\n",
    "        elif 'iPSC' in t.cell.values:\n",
    "            t = t[t.cell == 'iPSC']\n",
    "        if t.shape[0] == 1:\n",
    "            keep.append(t.index[0])\n",
    "        else:\n",
    "            print('?: {}'.format(i))\n",
    "\n",
    "wgs = wgs.drop(set(wgs[wgs.subject_id.apply(lambda x: x in vc.index)].index) - set(keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wgs = wgs.drop(['name', 'clone', 'passage', 'day', 'status', 'comment', 'sequence_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subject = subject_subject.copy(deep=True)\n",
    "subject.index = subject['id']\n",
    "subject = subject.ix[set(rna.subject_id) | set(wgs.subject_id)]\n",
    "subject = subject[['sex', 'age', 'family_id', 'father_id', 'mother_id', \n",
    "                   'twin_id', 'ethnicity_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn = os.path.join(outdir, 'cnvs.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    cnv.to_csv(fn, sep='\\t')\n",
    "    \n",
    "rna.index.name = 'sample_id'\n",
    "fn = os.path.join(outdir, 'rnaseq_metadata.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    rna.to_csv(fn, sep='\\t')\n",
    "    \n",
    "fn = os.path.join(outdir, 'subject_metadata.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    subject.to_csv(fn, sep='\\t')\n",
    "    \n",
    "fn = os.path.join(outdir, 'wgs_metadata.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    wgs.to_csv(fn, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA-seq Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dy = '/projects/CARDIPS/pipeline/RNAseq/combined_files'\n",
    "# STAR logs.\n",
    "fn = os.path.join(dy, 'star_logs.tsv')\n",
    "logs = pd.read_table(fn, index_col=0, low_memory=False)\n",
    "logs = logs.ix[rna.index]\n",
    "logs.index.name = 'sample_id'\n",
    "\n",
    "fn = os.path.join(outdir, 'star_logs.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    logs.to_csv(fn, sep='\\t')\n",
    "    \n",
    "# Expression values.\n",
    "fn = os.path.join(dy, 'rsem_tpm.tsv')\n",
    "tpm = pd.read_table(fn, index_col=0, low_memory=False)\n",
    "tpm = tpm[rna.index]\n",
    "fn = os.path.join(outdir, 'rsem_tpm.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    tpm.to_csv(fn, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Add ASE results when finished."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Allele counts.\n",
    "cpy.makedir(os.path.join(private_outdir, 'allele_counts'))\n",
    "fns = glob.glob('/raid3/projects/CARDIPS/pipeline/RNAseq/*/'\n",
    "                'results/*mbased/*mbased_input.tsv')\n",
    "fns = [x for x in fns if os.path.split(x)[1].split('_')[0] in rnaseq.index]\n",
    "for fn in fns:\n",
    "    new_fn = os.path.join(private_outdir, 'allele_counts', os.path.split(fn)[1])\n",
    "    if not os.path.exists(new_fn):\n",
    "        os.symlink(fn, new_fn)\n",
    "        \n",
    "# MBASED ASE results.\n",
    "cpy.makedir(os.path.join(outdir, 'mbased_locus'))\n",
    "fns = glob.glob('/raid3/projects/CARDIPS/pipeline/RNAseq/*/results/*mbased/*_locus.tsv')\n",
    "fns = [x for x in fns if os.path.split(x)[1].split('_')[0] in rnaseq.index]\n",
    "for fn in fns:\n",
    "    new_fn = os.path.join(outdir, 'mbased_locus', os.path.split(fn)[1])\n",
    "    if not os.path.exists(new_fn):\n",
    "        os.symlink(fn, new_fn)\n",
    "        \n",
    "cpy.makedir(os.path.join(private_outdir, 'mbased_snv'))\n",
    "fns = glob.glob('/raid3/projects/CARDIPS/pipeline/RNAseq/*/results/*mbased/*_snv.tsv')\n",
    "fns = [x for x in fns if os.path.split(x)[1].split('_')[0] in rnaseq.index]\n",
    "for fn in fns:\n",
    "    new_fn = os.path.join(private_outdir, 'mbased_snv', os.path.split(fn)[1])\n",
    "    if not os.path.exists(new_fn):\n",
    "        os.symlink(fn, new_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATAC-seq Peaks"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "cpy.makedir(os.path.join(outdir, 'atac_seq'))\n",
    "samples = ['83dacb11-4180-4807-b099-05fd1561a722',\n",
    "           'e932e556-59a6-4f70-9b4c-ef5f69dac3ce',\n",
    "           'f549b5fa-a6c0-49fb-8a07-dda4f72ff076']\n",
    "for s in samples:\n",
    "    fn = os.path.join('/raid3/projects/CARDIPS/pipeline/ATACseq/'\n",
    "                      'merged/{0}_time_course_day_0_merged_macs2/'\n",
    "                      '{0}_time_course_day_0_merged_peaks.narrowPeak'.format(s))\n",
    "    new_fn = os.path.join(outdir, 'atac_seq', os.path.split(fn)[1])\n",
    "    if not os.path.exists(new_fn):\n",
    "        os.symlink(fn, new_fn)\n",
    "    fn = os.path.join('/raid3/projects/CARDIPS/pipeline/ATACseq/'\n",
    "                      'merged/{0}_time_course_day_0_merged_macs2/'\n",
    "                      '{0}_time_course_day_0_merged_summits.bed'.format(s))\n",
    "    new_fn = os.path.join(outdir, 'atac_seq', os.path.split(fn)[1])\n",
    "    if not os.path.exists(new_fn):\n",
    "        os.symlink(fn, new_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain Files\n",
    "\n",
    "I need to convert some mouse coordinates to hg19 and some hg20 coordinates\n",
    "to hg19 as well."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import shutil\n",
    "from urllib2 import urlopen\n",
    "\n",
    "def download_and_gunzip(url, dest):\n",
    "    \"\"\"\n",
    "    Download a gzipped file url to dest and gunzip it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        URL for gzipped file to download.\n",
    "\n",
    "    dest : str\n",
    "        Full path to save gzipped file to. This file will be gunzipped.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(os.path.split(dest)[0])\n",
    "    except OSError:\n",
    "        pass\n",
    "    req = urlopen(url)\n",
    "    with open(dest, 'w') as d:\n",
    "        shutil.copyfileobj(req, d)\n",
    "    subprocess.check_call(['gunzip', dest])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "url = 'http://hgdownload.cse.ucsc.edu/goldenPath/mm9/vsHg19/mm9.hg19.all.chain.gz'\n",
    "dest = os.path.join(outdir, 'mm9.hg19.all.chain.gz')\n",
    "if not os.path.exists(dest):\n",
    "    download_and_gunzip(url, dest)\n",
    "url = 'http://hgdownload.cse.ucsc.edu/goldenPath/hg38/liftOver/hg38ToHg19.over.chain.gz'\n",
    "dest = os.path.join(outdir, 'hg38ToHg19.over.chain.gz')\n",
    "if not os.path.exists(dest):\n",
    "    download_and_gunzip(url, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = os.path.join(private_outdir, 'autosomal_variants.vcf.gz')\n",
    "if not os.path.exists(fn):\n",
    "    os.symlink('/projects/CARDIPS/pipeline/WGS/mergedVCF/CARDIPS_201512.PASS.vcf.gz',\n",
    "               fn)\n",
    "    os.symlink('/projects/CARDIPS/pipeline/WGS/mergedVCF/CARDIPS_201512.PASS.vcf.gz.tbi',\n",
    "               fn + '.tbi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
