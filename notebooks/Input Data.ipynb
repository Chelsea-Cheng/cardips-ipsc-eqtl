{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data\n",
    "\n",
    "This notebook parses some of the CARDiPS files to take only data that we need for this project. \n",
    "This notebook will only run on the Frazer lab cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import cdpybio as cpb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import ciepy\n",
    "import cardipspy as cpy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outdir = os.path.join(ciepy.root, 'output',\n",
    "                      'input_data')\n",
    "cpy.makedir(outdir)\n",
    "\n",
    "private_outdir = os.path.join(ciepy.root, 'private_output',\n",
    "                              'input_data')\n",
    "cpy.makedir(private_outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dy = '/projects/CARDIPS/data/database/20160129'\n",
    "\n",
    "fn = os.path.join(dy, 'baseline_analyte.tsv')\n",
    "baseline_analyte = pd.read_table(fn, index_col=1)\n",
    "fn = os.path.join(dy, 'baseline_wgsisaac.tsv')\n",
    "baseline_wgsisaac = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'baseline_ipsc.tsv')\n",
    "baseline_ipsc = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'baseline_wgs.tsv')\n",
    "baseline_wgs = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'baseline_cnv.tsv')\n",
    "baseline_cnv = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'baseline_rnas.tsv')\n",
    "baseline_rnas = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'baseline_ibd.tsv')\n",
    "baseline_ibd = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'baseline_snpa.tsv')\n",
    "baseline_snpa = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'baseline_tissue.tsv')\n",
    "baseline_tissue = pd.read_table(fn, index_col=1)\n",
    "\n",
    "fn = os.path.join(dy, 'family1070_rnas.tsv')\n",
    "family1070_rnas = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'family1070_tissue.tsv')\n",
    "family1070_tissue = pd.read_table(fn, index_col=1)\n",
    "\n",
    "fn = os.path.join(dy, 'subject_pedigree.tsv')\n",
    "subject_pedigree = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'subject_family.tsv')\n",
    "subject_family = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'subject_subject.tsv')\n",
    "subject_subject = pd.read_table(fn, index_col=3)\n",
    "\n",
    "# The only columns that I should use from data_* tables\n",
    "# are the seq_id and status columns. Others may be wrong.\n",
    "fn = os.path.join(dy, 'data_wgs.tsv')\n",
    "data_wgs = pd.read_table(fn, index_col=2)\n",
    "fn = os.path.join(dy, 'data_snpa.tsv')\n",
    "data_snpa = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'data_array.tsv')\n",
    "data_array = pd.read_table(fn, index_col=0)\n",
    "# fn = os.path.join(dy, 'data_chips.tsv')\n",
    "# data_chips = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'data_atacs.tsv')\n",
    "data_atacs = pd.read_table(fn, index_col=0)\n",
    "# fn = os.path.join(dy, 'data_metha.tsv')\n",
    "# data_metha = pd.read_table(fn, index_col=0)\n",
    "# fn = os.path.join(dy, 'data_hic.tsv')\n",
    "# data_hic = pd.read_table(fn, index_col=0)\n",
    "fn = os.path.join(dy, 'data_rnas.tsv')\n",
    "data_rnas = pd.read_table(fn, index_col=2)\n",
    "fn = os.path.join(dy, 'data_sequence.tsv')\n",
    "data_sequence = pd.read_table(fn, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array CNVs\n",
    "\n",
    "I'm going to make a table of all CNVs identified by arrays. Some iPSC didn't have\n",
    "any CNVs. For now, if an iPSC is in the CNV table, that means that it either\n",
    "didn't have CNVs or we didn't test that clone/passage number for CNVs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnv = baseline_cnv.merge(baseline_snpa, left_on='snpa_id', right_index=True,\n",
    "                         suffixes=['_cnv', '_snpa'])\n",
    "cnv = cnv.merge(baseline_analyte, left_on='analyte_id', right_index=True,\n",
    "                suffixes=['_cnv', '_analyte'])\n",
    "cnv = cnv.merge(baseline_tissue, left_on='tissue_id', right_index=True,\n",
    "                suffixes=['_cnv', '_tissue'])\n",
    "cnv = cnv[['type', 'chr', 'start', 'end', 'len', 'primary_detect_method', \n",
    "           'clone', 'passage', 'subject_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA-seq Samples for this Study\n",
    "\n",
    "I'm going to use baseline and family 1070 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get family1070 samples.\n",
    "tdf = family1070_rnas[family1070_rnas.comment.isnull()]\n",
    "tdf = tdf.merge(family1070_tissue, left_on='tissue_id', right_index=True, \n",
    "                suffixes=['_rna', '_tissue'])\n",
    "tdf = tdf[tdf.cell_type == 'iPSC']\n",
    "tdf.index = tdf.rnas_id\n",
    "tdf['status'] = data_rnas.ix[tdf.index, 'status']\n",
    "tdf = tdf[tdf.status == 0]\n",
    "tdf = tdf[['ipsc_clone_number', 'ipsc_passage', 'subject_id']]\n",
    "tdf.columns = ['clone', 'passage', 'subject_id']\n",
    "tdf['isolated_by'] = 'p'\n",
    "tdf.index.name = 'rna_id'\n",
    "\n",
    "# Get the iPSC eQTL samples.\n",
    "rna = baseline_rnas[baseline_rnas.rnas_id.isnull() == False]\n",
    "rna.index = rna.rnas_id\n",
    "rna.index.name = 'rna_id'\n",
    "rna['status'] = data_rnas.ix[rna.index, 'status']\n",
    "rna = rna[rna.status == 0]\n",
    "#rna = rna.ix[censor[censor == False].index]\n",
    "rna = rna.merge(baseline_analyte, left_on='analyte_id', right_index=True,\n",
    "                suffixes=['_rnas', '_analyte'])\n",
    "rna = rna.merge(baseline_tissue, left_on='tissue_id', right_index=True,\n",
    "                suffixes=['_rnas', '_tissue'])\n",
    "rna = rna[['clone', 'passage', 'subject_id']]\n",
    "rna['isolated_by'] = 'a'\n",
    "\n",
    "rna = pd.concat([rna, tdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 215 of the 222 subjects in the \"222 cohort.\"\n"
     ]
    }
   ],
   "source": [
    "# Get 222 subjects.\n",
    "cohort222 = baseline_ipsc.merge(baseline_tissue, left_on='tissue_id', \n",
    "                                right_index=True,  suffixes=['_ipsc', '_tissue'])\n",
    "n = len(set(rna.subject_id) & set(cohort222.subject_id))\n",
    "print('We have {} of the 222 subjects in the \"222 cohort.\"'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rna['sequence_id'] = data_rnas.ix[rna.index, 'sequence_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can use all of these samples that passed QC for various expression analyses.\n",
    "\n",
    "### eQTL samples\n",
    "\n",
    "Now I'm going to identify one sample per subject to use for eQTL analysis.\n",
    "\n",
    "I'll start by keeping samples whose clone/passage number matches up with \n",
    "those from the 222 cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rna['in_eqtl'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = (cohort222.subject_id + ':' + cohort222.clone.astype(int).astype(str) + \n",
    "           ':' + cohort222.passage.astype(int).astype(str))\n",
    "\n",
    "t = rna.dropna(subset=['passage'])\n",
    "t.loc[:, ('sample')] = (t.subject_id + ':' + t.clone.astype(int).astype(str) + \n",
    "                        ':' + t.passage.astype(int).astype(str))\n",
    "t = t[t['sample'].apply(lambda x: x in samples.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These samples are in the 222 cohort and the eQTL analysis.\n",
    "rna['in_222'] = False\n",
    "rna.ix[t.index, 'in_222'] = True\n",
    "rna.ix[t.index, 'in_eqtl'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll add in any samples for which we have CNVs but weren't in the 222."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = (cnv.subject_id + ':' + cnv.clone.astype(int).astype(str) + \n",
    "           ':' + cnv.passage.astype(int).astype(str))\n",
    "\n",
    "t = rna.dropna(subset=['passage'])\n",
    "t.loc[:, ('sample')] = (t.subject_id + ':' + t.clone.astype(int).astype(str) + \n",
    "                        ':' + t.passage.astype(int).astype(str))\n",
    "t = t[t['sample'].apply(lambda x: x in samples.values)]\n",
    "t = t[t.subject_id.apply(lambda x: x not in rna.ix[rna.in_eqtl, 'subject_id'].values)]\n",
    "\n",
    "# These samples aren't in the 222 but we have a measured CNV for them.\n",
    "rna.ix[t.index, 'in_eqtl'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll add in samples where the clone was in the 222 but we don't have the same passage\n",
    "number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = (cohort222.subject_id + ':' + cohort222.clone.astype(int).astype(str))\n",
    "\n",
    "t = rna[rna.in_eqtl == False]\n",
    "t = t[t.subject_id.apply(lambda x: x not in rna.ix[rna.in_eqtl, 'subject_id'].values)]\n",
    "t['samples'] = t.subject_id + ':' + t.clone.astype(int).astype(str)\n",
    "t = t[t.samples.apply(lambda x: x in samples.values)]\n",
    "\n",
    "# These clones are in the 222, we just have a different passage number.\n",
    "rna['clone_in_222'] = False\n",
    "rna.ix[rna.in_222, 'clone_in_222'] = True\n",
    "rna.ix[t.index, 'clone_in_222'] = True\n",
    "rna.ix[t.index, 'in_eqtl'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll add in any samples from subjects we don't yet have in the eQTL analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = rna[rna.in_eqtl == False]\n",
    "t = t[t.subject_id.apply(lambda x: x not in rna.ix[rna.in_eqtl, 'subject_id'].values)]\n",
    "\n",
    "rna.ix[t.index, 'in_eqtl'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We potentially have 215 distinct subjects in the eQTL analysis.\n"
     ]
    }
   ],
   "source": [
    "n = rna.in_eqtl.value_counts()[True]\n",
    "print('We potentially have {} distinct subjects in the eQTL analysis.'.format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WGS Samples\n",
    "\n",
    "Now I'll assign WGS IDs for each RNA-seq sample. Some subjects have multiple WGS samples\n",
    "for different cell types. I'll preferentially use blood, fibroblast, and finally iPSC WGS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wgs = baseline_wgs.merge(baseline_analyte, left_on='analyte_id', right_index=True,\n",
    "                         suffixes=['_wgs', '_analyte'])\n",
    "wgs = wgs.merge(baseline_tissue, left_on='tissue_id', right_index=True,\n",
    "                  suffixes=['_wgs', '_tissue'])\n",
    "wgs = wgs.merge(baseline_analyte, left_on='analyte_id', right_index=True,\n",
    "                  suffixes=['_wgs', '_analyte'])\n",
    "wgs = wgs.dropna(subset=['wgs_id'])\n",
    "wgs.index = wgs.wgs_id\n",
    "wgs['status'] = data_wgs.ix[wgs.index, 'status']\n",
    "wgs = wgs[wgs.status == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rna['wgs_id'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in rna.index:\n",
    "    s = rna.ix[i, 'subject_id']\n",
    "    t = wgs[wgs.subject_id == s]\n",
    "    if t.shape[0] == 1:\n",
    "        rna.ix[i, 'wgs_id'] = t.index[0]\n",
    "    elif t.shape[0] > 1:\n",
    "        if 'Blood' in t.source.values:\n",
    "            t = t[t.source == 'Blood']\n",
    "        elif 'iPSC' in t.source.values:\n",
    "            t = t[t.source == 'iPSC']\n",
    "        if t.shape[0] == 1:\n",
    "            rna.ix[i, 'wgs_id'] = t.index[0]\n",
    "        else:\n",
    "            print('?: {}'.format(i))\n",
    "    else:\n",
    "        #print('No WGS: {}'.format(i))\n",
    "        print('No WGS: {}'.format(rna.ix[i, 'subject_id']))\n",
    "        rna.ix[i, 'in_eqtl'] = False\n",
    "\n",
    "rna.ix[rna['wgs_id'] == '', 'wgs_id'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are left with 215 subjects for the eQTL analysis.\n"
     ]
    }
   ],
   "source": [
    "n = rna.in_eqtl.value_counts()[True]\n",
    "print('We are left with {} subjects for the eQTL analysis.'.format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to keep one WGS sample per person in the cohort \n",
    "(preferentially blood, fibroblast, and finally iPSC) even if we don't\n",
    "have RNA-seq in case we want to look at phasing etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vc = wgs.subject_id.value_counts()\n",
    "vc = vc[vc > 1]\n",
    "\n",
    "keep = []\n",
    "for s in vc.index:\n",
    "    t = wgs[wgs.subject_id == s]\n",
    "    if t.shape[0] == 1:\n",
    "        keep.append(t.index[0])\n",
    "    elif t.shape[0] > 1:\n",
    "        if 'Blood' in t.source.values:\n",
    "            t = t[t.source == 'Blood']\n",
    "        elif 'iPSC' in t.source.values:\n",
    "            t = t[t.source == 'iPSC']\n",
    "        if t.shape[0] == 1:\n",
    "            keep.append(t.index[0])\n",
    "        else:\n",
    "            print('?: {}'.format(i))\n",
    "\n",
    "wgs = wgs.drop(set(wgs[wgs.subject_id.apply(lambda x: x in vc.index)].index) - set(keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wgs = wgs[['source', 'subject_id']]\n",
    "wgs.columns = ['cell', 'subject_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subject = subject_subject.copy(deep=True)\n",
    "subject = subject.ix[set(rna.subject_id) | set(wgs.subject_id)]\n",
    "subject = subject[['sex', 'age', 'family_id', 'father_id', 'mother_id', \n",
    "                   'twin_id', 'ethnicity_group']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to define a set of unrelated individuals to use for some analyses. There \n",
    "are unrelated people in some families due to marriage, but I will just choose one person\n",
    "from each family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unrelateds = rna[rna.in_eqtl]\n",
    "unrelateds = unrelateds.merge(subject, left_on='subject_id', right_index=True)\n",
    "unrelateds = unrelateds.drop_duplicates(subset=['family_id'])\n",
    "rna['in_unrelateds'] = False\n",
    "rna.ix[unrelateds.index, 'in_unrelateds'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = os.path.join(outdir, 'cnvs.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    cnv.to_csv(fn, sep='\\t')\n",
    "    \n",
    "rna.index.name = 'sample_id'\n",
    "fn = os.path.join(outdir, 'rnaseq_metadata.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    rna.to_csv(fn, sep='\\t')\n",
    "    \n",
    "fn = os.path.join(outdir, 'subject_metadata.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    subject.to_csv(fn, sep='\\t')\n",
    "    \n",
    "fn = os.path.join(outdir, 'wgs_metadata.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    wgs.to_csv(fn, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA-seq Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dy = '/projects/CARDIPS/pipeline/RNAseq/combined_files'\n",
    "# STAR logs.\n",
    "fn = os.path.join(dy, 'star_logs.tsv')\n",
    "logs = pd.read_table(fn, index_col=0, low_memory=False)\n",
    "logs = logs.ix[rna.index]\n",
    "logs.index.name = 'sample_id'\n",
    "\n",
    "fn = os.path.join(outdir, 'star_logs.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    logs.to_csv(fn, sep='\\t')\n",
    "    \n",
    "# Expression values.\n",
    "fn = os.path.join(dy, 'rsem_tpm.tsv')\n",
    "tpm = pd.read_table(fn, index_col=0, low_memory=False)\n",
    "tpm = tpm[rna.index]\n",
    "fn = os.path.join(outdir, 'rsem_tpm.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    tpm.to_csv(fn, sep='\\t')\n",
    "    \n",
    "fn = os.path.join(dy, 'rsem_expected_counts.tsv')\n",
    "ec = pd.read_table(fn, index_col=0, low_memory=False)\n",
    "ec = ec[rna.index]\n",
    "fn = os.path.join(outdir, 'rsem_expected_counts.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    ec.to_csv(fn, sep='\\t')\n",
    "    \n",
    "ec_sf = cpb.analysis.deseq2_size_factors(ec.astype(int), meta=rna, design='~subject_id')\n",
    "fn = os.path.join('rsem_expected_counts_size_factors.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    ec_sf.to_csv(fn, sep='\\t')\n",
    "    \n",
    "ec_n = (ec / ec_sf)\n",
    "fn = os.path.join(outdir, 'rsem_expected_counts_norm.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    ec_n.to_csv(fn, sep='\\t')\n",
    "    \n",
    "fn = os.path.join(dy, 'gene_counts.tsv')\n",
    "gc = pd.read_table(fn, index_col=0, low_memory=False)\n",
    "gc = gc[rna.index]\n",
    "fn = os.path.join(outdir, 'gene_counts.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    gc.to_csv(fn, sep='\\t')\n",
    "\n",
    "gc_sf = cpb.analysis.deseq2_size_factors(gc, meta=rna, design='~subject_id')\n",
    "fn = os.path.join(outdir, 'gene_counts_size_factors.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    gc_sf.to_csv(fn, sep='\\t')\n",
    "    \n",
    "gc_n = (gc / gc_sf)\n",
    "fn = os.path.join(outdir, 'gene_counts_norm.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    gc_n.to_csv(fn, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Allele counts.\n",
    "cpy.makedir(os.path.join(private_outdir, 'allele_counts'))\n",
    "fns = glob.glob('/projects/CARDIPS/pipeline/RNAseq/sample/'\n",
    "                '*/*mbased/*mbased_input.tsv')\n",
    "fns = [x for x in fns if x.split('/')[-3] in rna.index]\n",
    "for fn in fns:\n",
    "    new_fn = os.path.join(private_outdir, 'allele_counts', os.path.split(fn)[1])\n",
    "    if not os.path.exists(new_fn):\n",
    "        os.symlink(fn, new_fn)\n",
    "        \n",
    "# MBASED ASE results.\n",
    "dy = '/projects/CARDIPS/pipeline/RNAseq/combined_files'\n",
    "df = pd.read_table(os.path.join(dy, 'mbased_major_allele_freq.tsv'), index_col=0)\n",
    "df = df[rna.index].dropna(how='all')\n",
    "df.to_csv(os.path.join(outdir, 'mbased_major_allele_freq.tsv'), sep='\\t')\n",
    "\n",
    "df = pd.read_table(os.path.join(dy, 'mbased_p_val_ase.tsv'), index_col=0)\n",
    "df = df[rna.index].dropna(how='all')\n",
    "df.to_csv(os.path.join(outdir, 'mbased_p_val_ase.tsv'), sep='\\t')\n",
    "\n",
    "df = pd.read_table(os.path.join(dy, 'mbased_p_val_het.tsv'), index_col=0)\n",
    "df = df[rna.index].dropna(how='all')\n",
    "df.to_csv(os.path.join(outdir, 'mbased_p_val_het.tsv'), sep='\\t')\n",
    "        \n",
    "cpy.makedir(os.path.join(private_outdir, 'mbased_snv'))\n",
    "fns = glob.glob('/projects/CARDIPS/pipeline/RNAseq/sample/*/*mbased/*_snv.tsv')\n",
    "fns = [x for x in fns if x.split('/')[-3] in rna.index]\n",
    "for fn in fns:\n",
    "    new_fn = os.path.join(private_outdir, 'mbased_snv', os.path.split(fn)[1])\n",
    "    if not os.path.exists(new_fn):\n",
    "        os.symlink(fn, new_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = os.path.join(private_outdir, 'autosomal_variants.vcf.gz')\n",
    "if not os.path.exists(fn):\n",
    "    os.symlink('/projects/CARDIPS/pipeline/WGS/mergedVCF/CARDIPS_201512.PASS.vcf.gz',\n",
    "               fn)\n",
    "    os.symlink('/projects/CARDIPS/pipeline/WGS/mergedVCF/CARDIPS_201512.PASS.vcf.gz.tbi',\n",
    "               fn + '.tbi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
