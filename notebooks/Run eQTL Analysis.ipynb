{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run eQTL Analysis\n",
    "\n",
    "This notebook coordinates and executes the eQTL analysis. This notebook is\n",
    "specialized for the Frazer lab cluster. Since running the entire analysis is \n",
    "time consuming, I generally run it \"by hand,\" starting jobs for groups of\n",
    "genes at different times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import datetime\n",
    "import glob\n",
    "import gzip\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "import cdpybio as cpb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pybedtools as pbt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import cardipspy as cpy\n",
    "import ciepy\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "random.seed(20150605)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outdir = os.path.join(ciepy.root, 'output',\n",
    "                      'run_eqtl_analysis')\n",
    "cpy.makedir(outdir)\n",
    "\n",
    "private_outdir = os.path.join(ciepy.root, 'private_output',\n",
    "                              'run_eqtl_analysis')\n",
    "cpy.makedir(private_outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gene_info = pd.read_table(cpy.gencode_gene_info, index_col=0)\n",
    "\n",
    "gold_eqtls = pd.read_table(os.path.join(ciepy.root, 'output', \n",
    "                                       'eqtl_methods_exploration',\n",
    "                                       'gold_eqtls.tsv'), index_col=0)\n",
    "\n",
    "fn = os.path.join(ciepy.root, 'output', 'eqtl_input', 'gene_to_regions.p')\n",
    "gene_to_regions = cPickle.load(open(fn, 'rb'))\n",
    "\n",
    "exp = pd.read_table(os.path.join(ciepy.root, 'output', 'eqtl_input', \n",
    "                                 'tpm_log_filtered_phe_std_norm_peer_resid.tsv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_emmax(gene_id):\n",
    "    os.chdir('/raid3/projects/CARDIPS/analysis/cardips-ipsc-eqtl/notebooks')\n",
    "    toutdir = os.path.join(outdir, 'results', gene_id)\n",
    "    if not os.path.exists(toutdir):\n",
    "        cpy.makedir(toutdir)\n",
    "        fn = os.path.join(toutdir, '{}.sh'.format(gene_id))\n",
    "        with open(fn, 'w') as f:\n",
    "            c = 'python {} \\\\\\n\\t'.format(os.path.join(ciepy.root, 'scripts', 'run_emmax.py'))\n",
    "            c += ' \\\\\\n\\t'.join([\n",
    "                    gene_id,\n",
    "                    os.path.join(ciepy.root, 'private_data', 'wgs', 'biallelic_snvs.vcf.gz'),\n",
    "                    ','.join(gene_to_regions[gene_id]),\n",
    "                    os.path.join(ciepy.root, 'output', 'eqtl_input', \n",
    "                                 'tpm_log_filtered_phe_std_norm_peer_resid.tsv'),\n",
    "                    os.path.join(ciepy.root, 'output', 'eqtl_input', 'emmax.ind'),\n",
    "                    os.path.join(ciepy.root, 'output', 'eqtl_input', 'wgs.kin'),\n",
    "                    toutdir,\n",
    "                    '-c {}'.format(os.path.join(ciepy.root, 'output', 'eqtl_input', \n",
    "                                                'emmax_sex_only.cov')),\n",
    "                ])\n",
    "            f.write(c + '\\n')\n",
    "        subprocess.check_call('bash {}'.format(fn), shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PBS\n",
    "\n",
    "Run jobs using PBS queue system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "todo = list(set(exp.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(outdir, 'results', '*'))]))\n",
    "todo = [x for x in todo if gene_info.ix[x, 'chrom'] not in ['chrX', 'chrY', 'chrM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_emmax_pbs(gene_ids, n=10):\n",
    "    \"\"\"\n",
    "    gene_ids is a list of gene_ids and n is the number of genes to submit at the same time.\n",
    "    This script will find n number of genes that EMMAX hasn't been run for and submit a job\n",
    "    for those genes.\n",
    "    \"\"\"\n",
    "    genes_todo = []\n",
    "    i = 0\n",
    "    while len(genes_todo) < n:\n",
    "        if not os.path.exists(os.path.join(outdir, 'results', gene_ids[i])):\n",
    "            genes_todo.append(gene_ids[i])\n",
    "        i += 1\n",
    "    res = datetime.datetime.now()\n",
    "    date = '{}-{:02d}-{:02d}-{:02d}-{:02d}-{:02d}'.format(res.year, res.month,\n",
    "                                                          res.day, res.hour,\n",
    "                                                          res.minute,\n",
    "                                                          res.second)\n",
    "    fn = os.path.join(outdir, 'results', 'pbs_scripts', '{}.pbs'.format(date))\n",
    "    with open(fn, 'w') as f:\n",
    "        f.write('#!/bin/bash\\n#PBS -q high\\n')\n",
    "        f.write('#PBS -N emmax_{}\\n'.format(date))\n",
    "        f.write('#PBS -l nodes=1:ppn=2\\n')\n",
    "        f.write('#PBS -o {}/emmax_{}.out\\n'.format(\n",
    "                os.path.join(outdir, 'results', 'pbs_scripts'), date))\n",
    "        f.write('#PBS -e {}/emmax_{}.err\\n\\n'.format(\n",
    "                    os.path.join(outdir, 'results', 'pbs_scripts'), date))\n",
    "        f.write('source activate cardips\\n')\n",
    "        f.write('source /raid3/projects/CARDIPS/pipeline/'\n",
    "                'cardips-data-software/environment.sh\\n\\n')\n",
    "        for gene_id in genes_todo:\n",
    "            toutdir = os.path.join(outdir, 'results', gene_id)\n",
    "            cpy.makedir(toutdir)\n",
    "            c = 'python {} \\\\\\n\\t'.format(os.path.join(ciepy.root, 'scripts', 'run_emmax.py'))\n",
    "            c += ' \\\\\\n\\t'.join([\n",
    "                    gene_id,\n",
    "                    os.path.join(ciepy.root, 'private_data', 'wgs', 'biallelic_snvs.vcf.gz'),\n",
    "                    ','.join(gene_to_regions[gene_id]),\n",
    "                    os.path.join(ciepy.root, 'output', 'eqtl_input', \n",
    "                                 'tpm_log_filtered_phe_std_norm_peer_resid.tsv'),\n",
    "                    os.path.join(ciepy.root, 'output', 'eqtl_input', 'emmax.ind'),\n",
    "                    os.path.join(ciepy.root, 'output', 'eqtl_input', 'wgs.kin'),\n",
    "                    toutdir,\n",
    "                    '-c {}'.format(os.path.join(ciepy.root, 'output', 'eqtl_input', \n",
    "                                                'emmax_sex_only.cov')),\n",
    "                ])\n",
    "            f.write(c + '\\n\\n')\n",
    "    cpy.submit_job(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if len(todo) > 0:\n",
    "    for i in range(10):\n",
    "        run_emmax_pbs(todo, n=20)\n",
    "        run_emmax_pbs(todo, n=20)\n",
    "        run_emmax_pbs(todo, n=20)\n",
    "        run_emmax_pbs(todo, n=20)\n",
    "        run_emmax_pbs(todo, n=20)\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for failed jobs\n",
    "\n",
    "Sometimes jobs I submit don't actually start. The code below checks for such\n",
    "jobs.\n",
    "\n",
    "Some genes have errors when they are running. These genes won't have `minimum_pvalues.tsv`\n",
    "files even when their job finishes. I want to identify these genes and remove their output\n",
    "directory so they will be run in a new job. I think these genes often leave behind their\n",
    "temp directory so I'll have to go delete those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = ('ssh cdeboever@flc.ucsd.edu \\'qstat -f | grep Job_Name > /raid3/projects/'\n",
    "     'CARDIPS/analysis/cardips-ipsc-eqtl/output/run_eqtl_analysis/'\n",
    "     'results/pbs_scripts/jnames.txt\\'')\n",
    "subprocess.check_call(c, shell=True)\n",
    "\n",
    "c = ('ssh cdeboever@flc.ucsd.edu \\'qstat -fn1 > /raid3/projects/'\n",
    "     'CARDIPS/analysis/cardips-ipsc-eqtl/output/run_eqtl_analysis/'\n",
    "     'results/pbs_scripts/qstatfn1.txt\\'')\n",
    "subprocess.check_call(c, shell=True)\n",
    "\n",
    "with open('/raid3/projects/CARDIPS/analysis/cardips-ipsc-eqtl/output/'\n",
    "          'run_eqtl_analysis/results/pbs_scripts/jnames.txt') as f:\n",
    "    jnames = [x.strip().split()[-1] for x in f.readlines()]\n",
    "    \n",
    "with open('/raid3/projects/CARDIPS/analysis/cardips-ipsc-eqtl/output/'\n",
    "          'run_eqtl_analysis/results/pbs_scripts/qstatfn1.txt') as f:\n",
    "    qstat = [x.split() for x in f.readlines()[5:]]\n",
    "qstat = pd.DataFrame(qstat)\n",
    "qstat.columns = ['job_id', 'username', 'queue', 'short_name',\n",
    "                  'sessid', 'nds', 'tsk', 'mem', 'time', \n",
    "                  'status', 'elap_time', 'node']\n",
    "qstat['job_id'] = qstat.job_id.apply(lambda x: x.split('.')[0])\n",
    "qstat['node'] = qstat.node.apply(lambda x: x.split('/')[0])\n",
    "qstat['name'] = jnames\n",
    "qstat.index = qstat.name\n",
    "qstat = qstat[qstat.username == 'cdeboeve']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_jobs = []\n",
    "for j in qstat.index:\n",
    "    fn = ('/raid3/projects/CARDIPS/analysis/cardips-ipsc-eqtl/output/'\n",
    "          'run_eqtl_analysis/results/pbs_scripts/{}.pbs'.format(j.replace('emmax_', '')))\n",
    "    if not os.path.exists(fn):\n",
    "        bad_jobs.append(qstat.ix[j, 'job_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qdel \n"
     ]
    }
   ],
   "source": [
    "print('qdel {}'.format(' '.join(bad_jobs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qstat['genes'] = [set() for i in range(qstat.shape[0])]\n",
    "qstat['started_genes'] = [set() for i in range(qstat.shape[0])]\n",
    "qstat['finished_genes'] = [set() for i in range(qstat.shape[0])]\n",
    "\n",
    "for j in qstat.index:\n",
    "    fn = ('/raid3/projects/CARDIPS/analysis/cardips-ipsc-eqtl/output/'\n",
    "          'run_eqtl_analysis/results/pbs_scripts/{}.pbs'.format(j.replace('emmax_', '')))\n",
    "    with open(fn) as f:\n",
    "        lines = [x.strip().split()[0] for x in f.readlines() if x.strip()[0:3] == 'ENS']\n",
    "    qstat.ix[j, 'genes'] = set(lines)\n",
    "    for g in lines:\n",
    "        if os.path.exists('/raid3/projects/CARDIPS/analysis/cardips-ipsc-eqtl/output/'\n",
    "                          'run_eqtl_analysis/results/{0}/{0}.tsv'.format(g)):\n",
    "            qstat.ix[j, 'started_genes'].add(g)\n",
    "        if os.path.exists('/raid3/projects/CARDIPS/analysis/cardips-ipsc-eqtl/output/'\n",
    "                          'run_eqtl_analysis/results/{0}/minimum_pvalues.tsv'.format(g)):\n",
    "            qstat.ix[j, 'finished_genes'].add(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "started_genes = frozenset().union(*qstat.started_genes)\n",
    "finished_genes = frozenset().union(*qstat.finished_genes)\n",
    "job_genes = frozenset().union(*qstat.genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_dys = glob.glob('/raid3/projects/CARDIPS/analysis/cardips-ipsc-eqtl/output/'\n",
    "                     'run_eqtl_analysis/results/ENS*')\n",
    "not_done = []\n",
    "for dy in gene_dys:\n",
    "    g = os.path.split(dy)[1]\n",
    "    if not os.path.exists(os.path.join(dy, 'minimum_pvalues.tsv')):\n",
    "        not_done.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# These are genes that aren't finished but aren't in\n",
    "# any of the current jobs. We can delete these directories.\n",
    "to_delete = set(not_done) - job_genes\n",
    "print(len(to_delete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for g in to_delete:\n",
    "    shutil.rmtree(os.path.join(outdir, 'results', g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I am specifying nodes individually because rcom is hanging up due to some \n",
    "# nodes that are offline.\n",
    "node_to_delete = {}\n",
    "nodes = set(qstat.node) - set(['--'])\n",
    "for node in nodes - set(['cn6']):\n",
    "    c = ('ssh cdeboever@flc.ucsd.edu \\'ssh {} \\'ls /dev/shm\\'\\''.format(node))\n",
    "    in_ram = set(subprocess.check_output(c, shell=True).strip().split('\\n')) - set([''])\n",
    "    t = qstat[qstat.node == node]\n",
    "    job_genes = frozenset().union(*t.genes)\n",
    "    to_delete = in_ram - job_genes\n",
    "    node_to_delete[node] = to_delete\n",
    "    if len(to_delete) > 0:\n",
    "        fn = os.path.join(ciepy.root, 'sandbox', '{}.sh'.format(node))\n",
    "        with open(fn, 'w') as f:\n",
    "            f.write('#!/bin/bash\\n\\n')\n",
    "            f.write('\\n'.join(['rm -r /dev/shm/{}'.format(x) for x in to_delete]) + '\\n')\n",
    "        c = ('ssh cdeboever@flc.ucsd.edu \\'ssh {} \\'bash {}\\'\\''.format(node, fn))\n",
    "        subprocess.check_call(c, shell=True)\n",
    "        os.remove(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2 +"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local\n",
    "\n",
    "Run jobs on fl1 using an IPython cluster. This code may need to be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_emmax(gene_id):\n",
    "    os.chdir('/raid3/projects/CARDIPS/analysis/cardips-ipsc-eqtl/notebooks')\n",
    "    toutdir = os.path.join(outdir, 'test_results', gene_id)\n",
    "    if not os.path.exists(toutdir):\n",
    "        ppy.makedir(toutdir)\n",
    "        fn = os.path.join(toutdir, '{}.sh'.format(gene_id))\n",
    "        with open(fn, 'w') as f:\n",
    "            c = 'python {} \\\\\\n\\t'.format(os.path.join(cpy.root, 'scripts', 'run_emmax.py'))\n",
    "            c += ' \\\\\\n\\t'.join([\n",
    "                    gene_id,\n",
    "                    os.path.join(cpy.root, 'private_data', 'wgs', 'biallelic_snvs.vcf.gz'),\n",
    "                    ','.join(gene_to_regions[gene_id]),\n",
    "                    os.path.join(cpy.root, 'output', 'eqtl_input', \n",
    "                                 'tpm_log_filtered_phe_std_norm_peer_resid.tsv'),\n",
    "                    os.path.join(cpy.root, 'output', 'eqtl_input', 'emmax.ind'),\n",
    "                    os.path.join(cpy.root, 'output', 'kinship_matrix', 'wgs.kin'),\n",
    "                    toutdir,\n",
    "                    '-c {}'.format(os.path.join(cpy.root, 'output', 'eqtl_input', \n",
    "                                                'emmax_sex_only.cov')),\n",
    "                ])\n",
    "            f.write(c + '\\n')\n",
    "        subprocess.check_call('bash {}'.format(fn), shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-07-18 08:16:45.402 [IPClusterStop] CRITICAL | Could not read pid file, cluster is probably not running.\r\n"
     ]
    }
   ],
   "source": [
    "!ipcluster stop --profile=cardips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ipcluster start -n 12 --daemon --profile=cardips\n",
    "!sleep 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.parallel import Client\n",
    "parallel_client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dview = parallel_client[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing os on engine(s)\n",
      "importing subprocess on engine(s)\n",
      "importing time on engine(s)\n",
      "importing ciepy on engine(s)\n",
      "importing projectpy on engine(s)\n"
     ]
    }
   ],
   "source": [
    "with dview.sync_imports():\n",
    "    import os\n",
    "    import subprocess\n",
    "    import time\n",
    "    import ciepy\n",
    "    import projectpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%px cpy = ciepy\n",
    "%px ppy = projectpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: _push>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dview.push(dict(gene_to_regions=gene_to_regions, outdir=outdir, run_emmax=run_emmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dview.scatter('todo', todo);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sleep = np.arange(0, 10 * len(parallel_client.ids), 10)\n",
    "dview.scatter('sleep', sleep);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%px time.sleep(sleep[0]) ; [run_emmax(x) for x in todo]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
