{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run eQTL Analysis\n",
    "\n",
    "This notebook coordinates and executes the eQTL analysis. This notebook is\n",
    "specialized for the Frazer lab cluster. Since running the entire analysis is \n",
    "time consuming, I generally run it \"by hand,\" starting jobs for groups of\n",
    "genes at different times. I've included instructions at various points below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import datetime\n",
    "import glob\n",
    "import gzip\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "import cdpybio as cpb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pybedtools as pbt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import vcf as pyvcf\n",
    "\n",
    "import cardipspy as cpy\n",
    "import ciepy\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "random.seed(20150605)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outdir = os.path.join(ciepy.root, 'output',\n",
    "                      'run_eqtl_analysis')\n",
    "cpy.makedir(outdir)\n",
    "\n",
    "private_outdir = os.path.join(ciepy.root, 'private_output',\n",
    "                              'run_eqtl_analysis')\n",
    "cpy.makedir(private_outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gene_info = pd.read_table(cpy.gencode_gene_info, index_col=0)\n",
    "\n",
    "fn = os.path.join(ciepy.root, 'output', 'eqtl_input', 'gene_to_regions.p')\n",
    "gene_to_regions = cPickle.load(open(fn, 'rb'))\n",
    "\n",
    "exp = pd.read_table(os.path.join(ciepy.root, 'output', 'eqtl_input', \n",
    "                                 'tpm_log_filtered_phe_std_norm_peer_resid.tsv'), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Analysis\n",
    "\n",
    "The `run_emmax_sge` method will submit a job for a gene. I currently ask for \n",
    "16Gb of RAM per job and four cores. If you ask for less cores, more jobs will run\n",
    "per node but all of the IO seems to slow the jobs down. Many genes probably need\n",
    "less than 16Gb of RAM but some need more. The `mem_needed` method was my attempt\n",
    "at estimating how much memory a job would need but it wasn't working well.\n",
    "I think the memory needed scales with the number of variants (which `num_variants`\n",
    "can tell you), so I could go and monitor the amount of memory used versus\n",
    "the number of variants. However, I didn't have a big problem with jobs failing when \n",
    "using 16Gb of memory (it seems like ~430 genes failed and had to be run again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cpy.makedir(os.path.join(private_outdir, 'sge_scripts'))\n",
    "cpy.makedir(os.path.join(private_outdir, 'logs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def num_variants(vcf, gene_id, tempdir, regions, samples, bcftools_path):\n",
    "    # This doesn't include CNVs but there aren't many of those.\n",
    "    import ciepy\n",
    "\n",
    "    samples = pd.read_table(samples, header=None, squeeze=True)\n",
    "    fn = os.path.join(tempdir, '{}.vcf.gz'.format(gene_id))\n",
    "    c = ('{} view {} -q 0.05:minor -m2 -M2 -r {} -s {} -O u | '\n",
    "         '{} filter -m x -O v | grep -v \\\\# | wc -l'.format(\n",
    "             bcftools_path,\n",
    "             vcf,\n",
    "             regions,\n",
    "             ','.join(samples.values),\n",
    "             bcftools_path,\n",
    "             fn))\n",
    "    num = int(subprocess.check_output(c, shell=True).strip())\n",
    "    return num\n",
    "\n",
    "def make_variant_cov(res_files, out):\n",
    "    vcf = os.path.join(ciepy.root, 'private_output/eqtl_input/filtered_all/0000.vcf.gz')\n",
    "    cnv_vcf = os.path.join(ciepy.root, 'private_output', 'cnv_processing', 'emmax_sorted.vcf.gz')\n",
    "    cov = os.path.join(ciepy.root, 'output', 'eqtl_input', 'emmax_sex_only.tsv')\n",
    "    covariates = pd.read_table(cov, index_col=0, header=None, squeeze=True)\n",
    "    new_covariates = pd.DataFrame({'sex':covariates})\n",
    "    for i,fn in enumerate(res_files):\n",
    "        res = ciepy.read_emmax_output(fn)\n",
    "        res = res[res.PVALUE == res.PVALUE.min()]\n",
    "        i = res.index[0]\n",
    "        if 'CNV' in res.ix[i, 'MARKER_ID']:\n",
    "            vcf_reader = pyvcf.Reader(open(cnv_vcf))\n",
    "        else:\n",
    "            vcf_reader = pyvcf.Reader(open(vcf))\n",
    "        res = vcf_reader.fetch(res.ix[i, 'CHROM'], res.ix[i, 'BEG'], res.ix[i,'END'])\n",
    "        r = res.next()\n",
    "        new_covariates[i] = 0\n",
    "        hets = set([x.sample for x in r.get_hets()]) & set(new_covariates.index)\n",
    "        halts = set([x.sample for x in r.get_hom_alts()]) & set(new_covariates.index)\n",
    "        new_covariates.ix[hets, i] = 1\n",
    "        new_covariates.ix[halts, i] = 2\n",
    "    new_covariates.to_csv(out, sep='\\t', header=None)\n",
    "\n",
    "def run_emmax_sge(gene_id, out_dy, mem=16, queue=None, res_files=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    vcf = os.path.join(ciepy.root, 'private_output/eqtl_input/filtered_all/0000.vcf.gz')\n",
    "    cnv_vcf = os.path.join(ciepy.root, 'private_output', 'cnv_processing', 'emmax_sorted.vcf.gz')\n",
    "    samples = os.path.join(ciepy.root, 'output', 'eqtl_input', 'emmax_samples.tsv')\n",
    "    regions = ','.join([x[3:] for x in gene_to_regions[gene_id]])\n",
    "    #num = num_variants(vcf, gene_id, outdir, regions, samples, 'bcftools')\n",
    "    #mem = mem_needed(num)\n",
    "    \n",
    "    exp = os.path.join(ciepy.root, 'output', 'eqtl_input', \n",
    "                       'tpm_log_filtered_phe_std_norm_peer_resid.tsv')\n",
    "    kin = os.path.join(ciepy.root, 'output', 'eqtl_input', 'wgs.kin')\n",
    "    toutdir = os.path.join(out_dy, gene_id)\n",
    "    cpy.makedir(toutdir)\n",
    "    cov = os.path.join(ciepy.root, 'output', 'eqtl_input', 'emmax_sex_only.tsv')\n",
    "    \n",
    "    # If one or more emmax results files are provided, we'll get the most significant\n",
    "    # variant from each file and add that as a covariate. We'll write the new covariate\n",
    "    # file in the gene's output directory.\n",
    "    if res_files:\n",
    "        covariates = pd.read_table(cov, index_col=0, header=None, squeeze=True)\n",
    "        for fn in res_files:\n",
    "            cov = os.path.join(toutdir, '{}.cov'.format(gene_id))\n",
    "            make_variant_cov(res_files, cov)\n",
    "\n",
    "    res = datetime.datetime.now()\n",
    "    date = re.sub(r'\\D', '_', str(res))\n",
    "    fn = os.path.join(private_outdir, 'sge_scripts', '{}_{}.sh'.format(gene_id, date))\n",
    "    with open(fn, 'w') as f:\n",
    "        f.write('#!/bin/bash\\n\\n')\n",
    "        f.write('#$ -N emmax_{}_{}\\n'.format(gene_id, date))\n",
    "        if queue:\n",
    "            f.write('#$ -l {}\\n'.format(queue))\n",
    "            if queue == 'opt':\n",
    "                mem = mem / 2.\n",
    "        num_threads = 4\n",
    "        f.write('#$ -l h_vmem={}G\\n'.format(mem / num_threads))\n",
    "        #f.write('#$ -l h_vmem=1G\\n')\n",
    "        f.write('#$ -pe smp {}\\n'.format(num_threads))\n",
    "        f.write('#$ -S /bin/bash\\n')\n",
    "        f.write('#$ -o {}/emmax_{}_{}.out\\n'.format(\n",
    "                os.path.join(private_outdir, 'logs'), gene_id, date))\n",
    "        f.write('#$ -e {}/emmax_{}_{}.err\\n\\n'.format(\n",
    "                    os.path.join(private_outdir, 'logs'), gene_id, date))\n",
    "        f.write('module load cardips/1\\n')\n",
    "        f.write('source activate cie\\n\\n')\n",
    "        \n",
    "        c = 'python {} \\\\\\n\\t'.format(os.path.join(ciepy.root, 'scripts', 'run_emmax.py'))\n",
    "        c += ' \\\\\\n\\t'.join([\n",
    "                gene_id,\n",
    "                '{},{}'.format(vcf, cnv_vcf),\n",
    "                regions,\n",
    "                exp,\n",
    "                samples,\n",
    "                kin,\n",
    "                toutdir,\n",
    "                '-c {}'.format(cov),\n",
    "            ])\n",
    "        f.write(c + '\\n\\n')\n",
    "    subprocess.check_call('qsub {}'.format(fn), shell=True)\n",
    "    #print(fn)\n",
    "    \n",
    "def get_jobs():\n",
    "    \"\"\"Get info about jobs currently running.\"\"\"\n",
    "    # Get jobs currently waiting to start or started.\n",
    "    running = !qstat -r | grep jobname\n",
    "    running = [x.split()[-1] for x in running if 'emmax_' in x]\n",
    "    # Get all submission scripts created.\n",
    "    fns = glob.glob(os.path.join(private_outdir, 'sge_scripts', '*.sh'))\n",
    "    jobnames = ['emmax_' + os.path.splitext(os.path.split(x)[1])[0] for x in fns]\n",
    "    genes = [os.path.split(x)[1].split('_')[0] for x in fns]\n",
    "    jobs = pd.DataFrame(np.array(fns).T, index=jobnames, columns=['path'])\n",
    "    jobs = pd.DataFrame([fns, genes], columns=jobnames, index=['path', 'gene']).T\n",
    "    jobs['status'] = 'finished'\n",
    "    # For now, running means either the job is waiting to start or has started.\n",
    "    jobs.ix[running, 'status'] = 'running'\n",
    "    return jobs\n",
    "\n",
    "def get_genes(jobs):\n",
    "    \"\"\"Get job info about genes that we are analyzing.\"\"\"\n",
    "    genes = [os.path.split(x)[1] for x in glob.glob(os.path.join(private_outdir, 'results', 'ENSG*'))]\n",
    "    genes = pd.DataFrame(index=genes)\n",
    "    genes['status'] = 'incomplete'\n",
    "    min_pvals = glob.glob(os.path.join(private_outdir, 'results', 'ENSG*', 'permuted_pvalues.tsv'))\n",
    "    genes.ix[[x.split('/')[-2] for x in min_pvals], 'status'] = 'complete'\n",
    "    genes['job_status'] = 'finished'\n",
    "    # If there is any running job with this gene, we want to mark the job_status\n",
    "    # as running.\n",
    "    genes.ix[jobs.ix[jobs.status == 'running', 'gene'], 'job_status'] = 'running'\n",
    "    return genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_failed():\n",
    "    # Write failed genes to file.\n",
    "    new_failed = list(genes[(genes.status == 'incomplete') & (genes.job_status == 'finished')].index)\n",
    "    if len(new_failed) > 0:\n",
    "        new_failed = list(genes[(genes.status == 'incomplete') & (genes.job_status == 'finished')].index)\n",
    "        if os.path.exists(os.path.join(private_outdir, 'failed.tsv')):\n",
    "            failed = pd.read_table(os.path.join(private_outdir, 'failed.tsv'), squeeze=True, \n",
    "                                   header=None, index_col=0)\n",
    "            if len(set(failed.index) & set(new_failed)) > 0:\n",
    "                failed[list(set(failed.index) & set(new_failed))] += 1\n",
    "            t = pd.Series(1, index=list(set(new_failed) - set(failed.index)))\n",
    "            failed = pd.concat([t, failed])\n",
    "        else:\n",
    "            failed = pd.Series(1, index=new_failed)\n",
    "        failed.to_csv(os.path.join(private_outdir, 'failed.tsv'), header=None, sep='\\t')\n",
    "\n",
    "        # Remove output directories.\n",
    "        dys = [os.path.join(private_outdir, 'results', g) for g in \n",
    "               genes[(genes.status == 'incomplete') & (genes.job_status == 'finished')].index]\n",
    "        c = ' ; '.join(['if [ -d \"{0}\" ]; then rm -r {0} ; fi'.format(dy) for dy in dys])\n",
    "        subprocess.check_call(c, shell=True)\n",
    "\n",
    "        # Delete temp directories if they exist.\n",
    "        dys = ['/dev/shm/{}'.format(g) for g in \n",
    "               genes[(genes.status == 'incomplete') & (genes.job_status == 'finished')].index]\n",
    "        s = ' ; '.join(['if [ -d \"{0}\" ]; then rm -r {0} ; fi'.format(dy) for dy in dys])\n",
    "        c = 'pdsh -g n \"{}\"'.format(s)\n",
    "        subprocess.check_call(c, shell=True)\n",
    "        \n",
    "def submit_failed(failed_fn):\n",
    "    # Submit failed genes with more memory.\n",
    "    if failed_fn:\n",
    "        jobs = get_jobs()\n",
    "        genes = get_genes(jobs)\n",
    "        failed = pd.read_table(failed_fn, index_col=0, \n",
    "                               header=None, squeeze=True)\n",
    "        todo = list(set(failed.index) - set(genes.index))\n",
    "        for gene in todo:\n",
    "            mem = (failed[gene] + 1) * 16\n",
    "            print(gene, mem)\n",
    "            run_emmax_sge(gene, mem=mem)\n",
    "            #run_emmax_sge(gene, mem=mem * 2, queue='opt')\n",
    "\n",
    "def submit_jobs(todo, out_dy, failed_fn, res_dys=None, failed=True, queue=None):\n",
    "    \"\"\"out_dy is the otuput directory where the per-gene output directories\n",
    "    will be stored. If failed == True, re-submit failed jobs. failed_fn is the \n",
    "    file that keeps track of which genes' jobs failed and how many times.\"\"\"\n",
    "    cpy.makedir(out_dy)\n",
    "    s = glob.glob(os.path.join(out_dy, '*'))\n",
    "    s = [os.path.split(x)[1] for x in s]\n",
    "    fns = glob.glob(os.path.join(out_dy, '*', 'permuted_pvalues.tsv'))\n",
    "    g = [x.split('/')[-2] for x in fns]\n",
    "    jobs = !qstat -r | grep jobname | tr -s ' ' | cut -d ' ' -f 4\n",
    "    jobs = [x for x in jobs if 'emmax' in x]\n",
    "    jobs = [x.split('_')[1] for x in jobs]\n",
    "\n",
    "    # Remove failed genes. I'll submit these with more memory.\n",
    "    if os.path.exists(failed_fn):\n",
    "        with open(failed_fn) as f:\n",
    "            failed = [x.strip() for x in f.readlines()]\n",
    "        todo = list(set(todo) - set(failed))\n",
    "\n",
    "    # Submit new jobs.\n",
    "    ind = 0\n",
    "    while ind < len(todo):\n",
    "        # Get prior results to use as covariate if needed.\n",
    "        if res_dys:\n",
    "            res_files = []\n",
    "            for dy in res_dys:\n",
    "                if os.path.exists(os.path.join(dy, todo[ind])):\n",
    "                    res_files.append(os.path.join(dy, todo[ind], todo[ind] + '.tsv'))\n",
    "        run_emmax_sge(todo[ind], out_dy, queue=queue, res_files=res_files)\n",
    "        ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_dy = os.path.join(private_outdir, 'results')\n",
    "failed_fn = os.path.join(private_outdir, 'failed.tsv')\n",
    "todo = list(set(exp.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(out_dy, '*'))]))\n",
    "todo = [x for x in todo if gene_info.ix[x, 'chrom'] not in ['chrX', 'chrY', 'chrM']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qvalues = pd.read_table(os.path.join(ciepy.root, 'output', 'eqtl_processing', 'secondary_eqtls',\n",
    "                                     'qvalues.tsv'), index_col=0)\n",
    "sig = qvalues[qvalues.sig]\n",
    "out_dy = os.path.join(private_outdir, 'results3')\n",
    "failed_fn = os.path.join(private_outdir, 'failed3.tsv')\n",
    "res_dys = [os.path.join(private_outdir, 'results'), os.path.join(private_outdir, 'results2')]\n",
    "cpy.makedir(out_dy)\n",
    "todo = list(set(sig.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(out_dy, '*'))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#submit_jobs(todo, out_dy, failed_fn, res_dys=res_dys, failed=True, queue=None)\n",
    "submit_jobs(todo, out_dy, failed_fn, res_dys=res_dys, failed=True, queue='opt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "3 + "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `all` queue\n",
    "\n",
    "This cell will submit jobs to the `all` queue. The variable `num_to_submit`\n",
    "controls how many jobs to submit.\n",
    "\n",
    "I just load balance the `all` and `opt` queues myself as the jobs finish. For instance,\n",
    "if I see the `opt` queue has a lot of jobs queued and `all` doesn't, I submit some jobs to\n",
    "`all`. I don't see a big difference in the speed between the two queues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "todo = list(set(exp.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(private_outdir, 'results', '*'))]))\n",
    "todo = [x for x in todo if gene_info.ix[x, 'chrom'] not in ['chrX', 'chrY', 'chrM']]\n",
    "\n",
    "# Remove failed genes. I'll wait to resubmit these with more memory.\n",
    "if os.path.exists(os.path.join(private_outdir, 'failed.txt')):\n",
    "    with open(os.path.join(private_outdir, 'failed.txt')) as f:\n",
    "        failed = [x.strip() for x in f.readlines()]\n",
    "    todo = list(set(todo) - set(failed))\n",
    "\n",
    "# Set num_to_submit to the number of jobs you want to submit.\n",
    "num_to_submit = len(todo)\n",
    "ind = 0\n",
    "while len(todo) > 0 and ind < num_to_submit:\n",
    "    run_emmax_sge(todo[ind])\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `opt` queue\n",
    "\n",
    "This cell will submit jobs to the `opt` queue. The variable `num_to_submit`\n",
    "controls how many jobs to submit. `run_emmax_sge` will cut the memory in half\n",
    "for `opt` jobs since they have less memory. If a gene fails in the `opt` queue \n",
    "due to memory it may work in the `all` queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "todo = list(set(exp.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(private_outdir, 'results', '*'))]))\n",
    "todo = [x for x in todo if gene_info.ix[x, 'chrom'] not in ['chrX', 'chrY', 'chrM']]\n",
    "\n",
    "# Remove failed genes. I'll wait to resubmit these with more memory.\n",
    "if os.path.exists(os.path.join(private_outdir, 'failed.txt')):\n",
    "    with open(os.path.join(private_outdir, 'failed.txt')) as f:\n",
    "        failed = [x.strip() for x in f.readlines()]\n",
    "    todo = list(set(todo) - set(failed))\n",
    "\n",
    "# Set num_to_submit to the number of jobs you want to submit.\n",
    "num_to_submit = len(todo)\n",
    "ind = 0\n",
    "while len(todo) > 0 and ind < num_to_submit:\n",
    "    run_emmax_sge(todo[ind], queue='opt')\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ENSG00000123243.10', 32)\n"
     ]
    }
   ],
   "source": [
    "# Submit failed genes with more memory.\n",
    "if os.path.exists(os.path.join(private_outdir, 'failed.tsv')):\n",
    "    jobs = get_jobs()\n",
    "    genes = get_genes(jobs)\n",
    "    failed = pd.read_table(os.path.join(private_outdir, 'failed.tsv'), index_col=0, \n",
    "                           header=None, squeeze=True)\n",
    "    todo = list(set(failed.index) - set(genes.index))\n",
    "    for gene in todo:\n",
    "        mem = (failed[gene] + 1) * 16\n",
    "        print(gene, mem)\n",
    "        run_emmax_sge(gene, mem=mem)\n",
    "        #run_emmax_sge(gene, mem=mem * 2, queue='opt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for failed jobs\n",
    "\n",
    "Some genes have errors when they are running. This can happen if I don't request enough memory \n",
    "for instance. Genes that fail won't have `minimum_pvalues.tsv` files even when their job finishes. \n",
    "I want to identify these genes and remove their output directory so they will be run in a new job. \n",
    "I think these genes often leave behind their temp directory so I have to go delete those too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17,769 total genes to do.\n"
     ]
    }
   ],
   "source": [
    "todo = list(set(exp.index))\n",
    "todo = [x for x in todo if gene_info.ix[x, 'chrom'] not in ['chrX', 'chrY', 'chrM']]\n",
    "print('{:,} total genes to do.'.format(len(todo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below shows how many genes' jobs are running. The number in the bottom\n",
    "left cell (incomplete, finished) indicates jobs that failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>job_status</th>\n",
       "      <th>finished</th>\n",
       "      <th>running</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>complete</th>\n",
       "      <td>17768</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incomplete</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "job_status  finished  running\n",
       "status                       \n",
       "complete       17768        0\n",
       "incomplete         0        1"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = get_jobs()\n",
    "genes = get_genes(jobs)\n",
    "\n",
    "pd.crosstab(genes.status, genes.job_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any genes that are incomplete but whose jobs are finished had errors. I need \n",
    "to delete their temp directories and the output directories and try resubmitting.\n",
    "I keep track of the failed genes so I can wait to resubmit them with more memory.\n",
    "The file `failed.tsv` has the gene ID and the number of times the gene failed. I\n",
    "increase the RAM in proportion to the number of times the gene fails. So if it has failed\n",
    "three times, I'll give it $3 * 16 = 48$ Gb of RAM the next time I submit, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write failed genes to file.\n",
    "new_failed = list(genes[(genes.status == 'incomplete') & (genes.job_status == 'finished')].index)\n",
    "if len(new_failed) > 0:\n",
    "    new_failed = list(genes[(genes.status == 'incomplete') & (genes.job_status == 'finished')].index)\n",
    "    if os.path.exists(os.path.join(private_outdir, 'failed.tsv')):\n",
    "        failed = pd.read_table(os.path.join(private_outdir, 'failed.tsv'), squeeze=True, \n",
    "                               header=None, index_col=0)\n",
    "        if len(set(failed.index) & set(new_failed)) > 0:\n",
    "            failed[list(set(failed.index) & set(new_failed))] += 1\n",
    "        t = pd.Series(1, index=list(set(new_failed) - set(failed.index)))\n",
    "        failed = pd.concat([t, failed])\n",
    "    else:\n",
    "        failed = pd.Series(1, index=new_failed)\n",
    "    failed.to_csv(os.path.join(private_outdir, 'failed.tsv'), header=None, sep='\\t')\n",
    "\n",
    "    # Remove output directories.\n",
    "    dys = [os.path.join(private_outdir, 'results', g) for g in \n",
    "           genes[(genes.status == 'incomplete') & (genes.job_status == 'finished')].index]\n",
    "    c = ' ; '.join(['if [ -d \"{0}\" ]; then rm -r {0} ; fi'.format(dy) for dy in dys])\n",
    "    subprocess.check_call(c, shell=True)\n",
    "\n",
    "    # Delete temp directories if they exist.\n",
    "    dys = ['/dev/shm/{}'.format(g) for g in \n",
    "           genes[(genes.status == 'incomplete') & (genes.job_status == 'finished')].index]\n",
    "    s = ' ; '.join(['if [ -d \"{0}\" ]; then rm -r {0} ; fi'.format(dy) for dy in dys])\n",
    "    c = 'pdsh -g n \"{}\"'.format(s)\n",
    "    subprocess.check_call(c, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes I may accidentally submit a job for a gene that already has a job submitted.\n",
    "This attempts to fix that."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Kill jobs and delete tempdirs for repeat genes. This is necessary when a job\n",
    "# is submitted (by accident) for a gene that is already complete.\n",
    "g = genes[genes.status + '-' + genes.job_status == 'complete-running'].index\n",
    "if len(g) > 0:\n",
    "    t = jobs[jobs.gene.apply(lambda x: x in g)]\n",
    "    for i in t.index:\n",
    "        try:\n",
    "            subprocess.check_call('qdel {}'.format(i), shell=True)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # Delete temp directories.\n",
    "\n",
    "    def chunks(l, n):\n",
    "        \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "        for i in xrange(0, len(l), n):\n",
    "            yield l[i:i+n]\n",
    "    cs = chunks(['/dev/shm/{}'.format(x) for x in g], 500)\n",
    "    while True:\n",
    "        try:\n",
    "            dys = cs.next()\n",
    "            s = ' ; '.join(['if [ -d \"{0}\" ]; then rm -r {0} ; fi'.format(dy) for dy in dys])\n",
    "            c = 'pdsh -g n \"{}\"'.format(s)\n",
    "            subprocess.check_call(c, shell=True)\n",
    "        except StopIteration:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2 + "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondary etc. QTLs\n",
    "\n",
    "I want to search for secondary, tertiary, etc. eQTLs for genes that had one significant\n",
    "eQTL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qvalues = pd.read_table(os.path.join(ciepy.root, 'output', 'eqtl_processing',\n",
    "                                     'qvalues.tsv'), index_col=0)\n",
    "sig = qvalues[qvalues.sig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "todo = list(set(sig.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(private_outdir, 'results2', '*'))]))\n",
    "\n",
    "# Remove failed genes. I'll wait to resubmit these with more memory.\n",
    "if os.path.exists(os.path.join(private_outdir, 'failed2.txt')):\n",
    "    with open(os.path.join(private_outdir, 'failed2.txt')) as f:\n",
    "        failed = [x.strip() for x in f.readlines()]\n",
    "    todo = list(set(todo) - set(failed))\n",
    "\n",
    "# Set num_to_submit to the number of jobs you want to submit.\n",
    "num_to_submit = len(todo) / 2\n",
    "ind = 0\n",
    "while len(todo) > 0 and ind < num_to_submit:\n",
    "    gene_id = todo[ind]\n",
    "    rfn = os.path.join(ciepy.root, 'private_output', 'run_eqtl_analysis', 'results',\n",
    "                       gene_id, '{}.tsv'.format(gene_id))\n",
    "    run_emmax_sge(gene_id, res_files=[rfn])\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "todo = list(set(sig.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(private_outdir, 'results2', '*'))]))\n",
    "\n",
    "# Remove failed genes. I'll wait to resubmit these with more memory.\n",
    "if os.path.exists(os.path.join(private_outdir, 'failed2.txt')):\n",
    "    with open(os.path.join(private_outdir, 'failed2.txt')) as f:\n",
    "        failed = [x.strip() for x in f.readlines()]\n",
    "    todo = list(set(todo) - set(failed))\n",
    "\n",
    "# Set num_to_submit to the number of jobs you want to submit.\n",
    "num_to_submit = len(todo)\n",
    "ind = 0\n",
    "while len(todo) > 0 and ind < num_to_submit:\n",
    "    gene_id = todo[ind]\n",
    "    rfn = os.path.join(ciepy.root, 'private_output', 'run_eqtl_analysis', 'results',\n",
    "                       gene_id, '{}.tsv'.format(gene_id))\n",
    "    run_emmax_sge(gene_id, queue='opt', res_files=[rfn])\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = glob.glob(os.path.join(private_outdir, 'results2', '*'))\n",
    "s = [os.path.split(x)[1] for x in s]\n",
    "fns = glob.glob(os.path.join(private_outdir, 'results2', '*', 'permuted_pvalues.tsv'))\n",
    "g = [x.split('/')[-2] for x in fns]\n",
    "jobs = !qstat -r | grep jobname | tr -s ' ' | cut -d ' ' -f 4\n",
    "jobs = [x for x in jobs if 'emmax' in x]\n",
    "jobs = [x.split('_')[1] for x in jobs]\n",
    "\n",
    "# Write failed genes to file.\n",
    "new_failed = set(s) - set(g) - set(jobs)\n",
    "if len(new_failed) > 0:\n",
    "    # new_failed = list(genes[(genes.status == 'incomplete') & (genes.job_status == 'finished')].index)\n",
    "    if os.path.exists(os.path.join(private_outdir, 'failed2.tsv')):\n",
    "        failed = pd.read_table(os.path.join(private_outdir, 'failed2.tsv'), squeeze=True, \n",
    "                               header=None, index_col=0)\n",
    "        if len(set(failed.index) & set(new_failed)) > 0:\n",
    "            failed[list(set(failed.index) & set(new_failed))] += 1\n",
    "        t = pd.Series(1, index=list(set(new_failed) - set(failed.index)))\n",
    "        failed = pd.concat([t, failed])\n",
    "    else:\n",
    "        failed = pd.Series(1, index=new_failed)\n",
    "    failed.to_csv(os.path.join(private_outdir, 'failed2.tsv'), header=None, sep='\\t')\n",
    "\n",
    "    # Remove output directories.\n",
    "    dys = [os.path.join(private_outdir, 'results2', g) for g in new_failed]\n",
    "    c = ' ; '.join(['if [ -d \"{0}\" ]; then rm -r {0} ; fi'.format(dy) for dy in dys])\n",
    "    subprocess.check_call(c, shell=True)\n",
    "\n",
    "    # Delete temp directories if they exist.\n",
    "    dys = ['/dev/shm/{}'.format(g) for g in new_failed]\n",
    "    s = ' ; '.join(['if [ -d \"{0}\" ]; then rm -r {0} ; fi'.format(dy) for dy in dys])\n",
    "    c = 'pdsh -g n \"{}\"'.format(s)\n",
    "    subprocess.check_call(c, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ENSG00000231389.3', 32)\n",
      "('ENSG00000196126.6', 32)\n",
      "('ENSG00000182372.6', 32)\n",
      "('ENSG00000213760.6', 32)\n",
      "('ENSG00000224557.3', 32)\n",
      "('ENSG00000254870.1', 32)\n",
      "('ENSG00000223865.6', 32)\n",
      "('ENSG00000263020.1', 32)\n",
      "('ENSG00000230313.1', 32)\n",
      "('ENSG00000179344.12', 32)\n",
      "('ENSG00000204287.9', 32)"
     ]
    }
   ],
   "source": [
    "# Submit failed genes with more memory.\n",
    "if os.path.exists(os.path.join(private_outdir, 'failed2.tsv')):\n",
    "    jobs = !qstat -r | grep jobname | tr -s ' ' | cut -d ' ' -f 4\n",
    "    jobs = [x for x in jobs if 'emmax' in x]\n",
    "    jobs = [x.split('_')[1] for x in jobs]\n",
    "    failed = pd.read_table(os.path.join(private_outdir, 'failed2.tsv'), index_col=0, \n",
    "                           header=None, squeeze=True)\n",
    "    todo = list(set(failed.index) - set(jobs))\n",
    "    for gene in todo:\n",
    "        mem = (failed[gene] + 1) * 16\n",
    "        print(gene, mem)\n",
    "        rfn = os.path.join(ciepy.root, 'private_output', 'run_eqtl_analysis', 'results',\n",
    "                           gene, '{}.tsv'.format(gene))\n",
    "        run_emmax_sge(gene, mem=mem * 2, queue='opt', res_files=[rfn])\n",
    "        #run_emmax_sge(gene, mem=mem, res_files=[rfn])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
