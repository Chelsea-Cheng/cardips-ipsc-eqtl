{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run eQTL Analysis\n",
    "\n",
    "This notebook coordinates and executes the eQTL analysis. This notebook is\n",
    "specialized for the Frazer lab cluster. Since running the entire analysis is \n",
    "time consuming, I generally run it \"by hand,\" starting jobs for groups of\n",
    "genes at different times. I've included instructions at various points below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import datetime\n",
    "import glob\n",
    "import gzip\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "import cdpybio as cpb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pybedtools as pbt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import vcf as pyvcf\n",
    "\n",
    "import cardipspy as cpy\n",
    "import ciepy\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "dy_name = 'run_eqtl_analysis'\n",
    "\n",
    "import socket\n",
    "if socket.gethostname() == 'fl-hn1' or socket.gethostname() == 'fl-hn2':\n",
    "    dy = os.path.join(ciepy.root, 'sandbox', dy_name)\n",
    "    cpy.makedir(dy)\n",
    "    pbt.set_tempdir(dy)\n",
    "    \n",
    "outdir = os.path.join(ciepy.root, 'output', dy_name)\n",
    "cpy.makedir(outdir)\n",
    "\n",
    "private_outdir = os.path.join(ciepy.root, 'private_output', dy_name)\n",
    "cpy.makedir(private_outdir)\n",
    "\n",
    "random.seed(20150605)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gene_info = pd.read_table(cpy.gencode_gene_info, index_col=0)\n",
    "\n",
    "fn = os.path.join(ciepy.root, 'output', 'eqtl_input', 'gene_to_regions.p')\n",
    "gene_to_regions = cPickle.load(open(fn, 'rb'))\n",
    "\n",
    "exp = pd.read_table(os.path.join(ciepy.root, 'output', 'eqtl_input', \n",
    "                                 'tpm_log_filtered_phe_std_norm_peer_resid.tsv'), index_col=0)\n",
    "\n",
    "fn = os.path.join(ciepy.root, 'output', 'input_data', 'rnaseq_metadata.tsv')\n",
    "rna_meta = pd.read_table(fn, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Analysis\n",
    "\n",
    "The `run_emmax_sge` method will submit a job for a gene. I currently ask for \n",
    "16Gb of RAM per job and four cores. If you ask for less cores, more jobs will run\n",
    "per node but all of the IO seems to slow the jobs down. Many genes probably need\n",
    "less than 16Gb of RAM but some need more. The `mem_needed` method was my attempt\n",
    "at estimating how much memory a job would need but it wasn't working well.\n",
    "I think the memory needed scales with the number of variants (which `num_variants`\n",
    "can tell you), so I could go and monitor the amount of memory used versus\n",
    "the number of variants. However, I didn't have a big problem with jobs failing when \n",
    "using 16Gb of memory (it seems like ~430 genes failed and had to be run again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def num_variants(vcf, gene_id, tempdir, regions, samples, bcftools_path):\n",
    "    \"\"\"\n",
    "    Count the number of variants to test for a gene. This currently \n",
    "    doesn't include CNVs but there aren't many of those.\n",
    "    \"\"\"\n",
    "    import ciepy\n",
    "\n",
    "    samples = pd.read_table(samples, header=None, squeeze=True)\n",
    "    fn = os.path.join(tempdir, '{}.vcf.gz'.format(gene_id))\n",
    "    c = ('{} view {} -q 0.01:minor -m2 -M2 -r {} -s {} -O u | '\n",
    "         '{} filter -m x -O v | grep -v \\\\# | wc -l'.format(\n",
    "             bcftools_path,\n",
    "             vcf,\n",
    "             regions,\n",
    "             ','.join(samples.values),\n",
    "             bcftools_path,\n",
    "             fn))\n",
    "    num = int(subprocess.check_output(c, shell=True).strip())\n",
    "    return num\n",
    "\n",
    "def make_variant_cov(res_files, out):\n",
    "    \"\"\"\n",
    "    Make a covariate (.cov) file for a gene including a covariate for each lead variant\n",
    "    in the EMMAX output files res_files.\n",
    "    \"\"\"\n",
    "    vcf = os.path.join(ciepy.root, 'private_output/eqtl_input/filtered_all/0000.vcf.gz')\n",
    "    gs_vcf = os.path.join(ciepy.root, 'private_output', 'cnv_processing', 'gs_emmax_sorted.vcf.gz')\n",
    "    lumpy_vcf = os.path.join(ciepy.root, 'private_output', 'cnv_processing', 'lumpy_emmax_sorted.vcf.gz')\n",
    "    cov = os.path.join(ciepy.root, 'output', 'eqtl_input', 'emmax_sex_only.tsv')\n",
    "    covariates = pd.read_table(cov, index_col=0, header=None, squeeze=True)\n",
    "    new_covariates = pd.DataFrame({'sex':covariates})\n",
    "    for i,fn in enumerate(res_files):\n",
    "        res = ciepy.read_emmax_output(fn)\n",
    "        res = res[res.PVALUE == res.PVALUE.min()]\n",
    "        i = res.index[0]\n",
    "        if 'CNV' in res.ix[i, 'MARKER_ID']:\n",
    "            vcf_reader = pyvcf.Reader(open(gs_vcf))\n",
    "        elif 'DUP' in res.ix[i, 'MARKER_ID'] or 'DEL' in res.ix[i, 'MARKER_ID']:\n",
    "            vcf_reader = pyvcf.Reader(open(lumpy_vcf))\n",
    "        else:\n",
    "            vcf_reader = pyvcf.Reader(open(vcf))\n",
    "        res = vcf_reader.fetch(res.ix[i, 'CHROM'], res.ix[i, 'BEG'], res.ix[i,'END'])\n",
    "        r = res.next()\n",
    "        new_covariates[i] = 0\n",
    "        hets = set([x.sample for x in r.get_hets()]) & set(new_covariates.index)\n",
    "        halts = set([x.sample for x in r.get_hom_alts()]) & set(new_covariates.index)\n",
    "        new_covariates.ix[hets, i] = 1\n",
    "        new_covariates.ix[halts, i] = 2\n",
    "    new_covariates.to_csv(out, sep='\\t', header=None)\n",
    "\n",
    "def run_emmax_sge(\n",
    "    gene_id, \n",
    "    out_dy,\n",
    "    ncores=4,\n",
    "    mem=16, \n",
    "    queue=None, \n",
    "    res_files=None,\n",
    "    samples=os.path.join(ciepy.root, 'output', 'eqtl_input', 'emmax_samples.tsv'),\n",
    "    cov=os.path.join(ciepy.root, 'output', 'eqtl_input', 'emmax_sex_only.tsv'),\n",
    "    exp=os.path.join(ciepy.root, 'output', 'eqtl_input', 'tpm_log_filtered_phe_std_norm_peer_resid.tsv'),\n",
    "    min_perm=1000,\n",
    "    max_perm=10000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run EMMAX for a given gene.\n",
    "    \"\"\"\n",
    "    vcf = os.path.join(ciepy.root, 'private_output/eqtl_input/filtered_all/0000.vcf.gz')\n",
    "    gs_vcf = os.path.join(ciepy.root, 'private_output', 'cnv_processing', 'gs_emmax_sorted.vcf.gz')\n",
    "    lumpy_vcf = os.path.join(ciepy.root, 'private_output', 'cnv_processing', 'lumpy_emmax_sorted.vcf.gz')\n",
    "    #samples = os.path.join(ciepy.root, 'output', 'eqtl_input', 'emmax_samples.tsv')\n",
    "    regions = ','.join([x[3:] for x in gene_to_regions[gene_id]])\n",
    "    \n",
    "    kin = os.path.join(ciepy.root, 'output', 'eqtl_input', 'wgs.kin')\n",
    "    toutdir = os.path.join(out_dy, 'gene_results', gene_id)\n",
    "    cpy.makedir(toutdir)\n",
    "    \n",
    "    # If one or more emmax results files are provided, we'll get the most significant\n",
    "    # variant from each file and add that as a covariate. We'll write the new covariate\n",
    "    # file in the gene's output directory.\n",
    "    if res_files:\n",
    "        covariates = pd.read_table(cov, index_col=0, header=None, squeeze=True)\n",
    "        for fn in res_files:\n",
    "            cov = os.path.join(toutdir, '{}.cov'.format(gene_id))\n",
    "            make_variant_cov(res_files, cov)\n",
    "\n",
    "    res = datetime.datetime.now()\n",
    "    date = re.sub(r'\\D', '_', str(res))\n",
    "    name = 'emmax_{}_{}_{}'.format(gene_id, date, os.path.split(out_dy)[1])\n",
    "    fn = os.path.join(out_dy, 'sge_scripts', '{}.sh'.format(name))\n",
    "    with open(fn, 'w') as f:\n",
    "        f.write('#!/bin/bash\\n\\n')\n",
    "        f.write('#$ -N {}\\n'.format(name))\n",
    "        if queue:\n",
    "            f.write('#$ -l {}\\n'.format(queue))\n",
    "        f.write('#$ -l h_vmem={}G\\n'.format(mem / ncores))\n",
    "        f.write('#$ -pe smp {}\\n'.format(ncores))\n",
    "        f.write('#$ -S /bin/bash\\n')\n",
    "        f.write('#$ -o {}/{}.out\\n'.format(\n",
    "                os.path.join(out_dy, 'logs'), name))\n",
    "        f.write('#$ -e {}/{}.err\\n\\n'.format(\n",
    "                os.path.join(out_dy, 'logs'), name))\n",
    "        f.write('module load cardips/1\\n')\n",
    "        f.write('source activate cie\\n\\n')\n",
    "        \n",
    "        c = 'python {} \\\\\\n\\t'.format(os.path.join(ciepy.root, 'scripts', 'run_emmax.py'))\n",
    "        c += ' \\\\\\n\\t'.join([\n",
    "                gene_id,\n",
    "                '{},{},{}'.format(vcf, gs_vcf, lumpy_vcf),\n",
    "                regions,\n",
    "                exp,\n",
    "                samples,\n",
    "                kin,\n",
    "                toutdir,\n",
    "                '-c {}'.format(cov),\n",
    "                '-i {}'.format(min_perm),\n",
    "                '-a {}'.format(max_perm),\n",
    "                '-m 0.01',\n",
    "            ])\n",
    "        f.write(c + '\\n\\n')\n",
    "    subprocess.check_call('qsub {}'.format(fn), shell=True)\n",
    "    #print(fn)\n",
    "    \n",
    "def get_jobs():\n",
    "    running = !qstat -r\n",
    "    running = [x for x in running if 'emmax_' in x]\n",
    "    if len(running) > 0:\n",
    "        jnames = [x.split()[-1] for x in running if 'jobname' in x]\n",
    "        status = [x.split()[4] for x in running if 'cdeboever' in x]\n",
    "        queue = [x.split()[-2].split('@')[0] for x in running if 'cdeboever' in x]\n",
    "        genes = [x.split('_')[1] for x in jnames]\n",
    "        out_dys = [x.split('_')[-1] for x in jnames]\n",
    "        submit_time = ['_'.join(x.split('_')[2:-1]) for x in jnames]\n",
    "        gene_out_dy = ['{}_{}'.format(genes[x], out_dys[x]) for x in range(len(genes))]\n",
    "        jobs = pd.DataFrame({'status':status, 'gene_id':genes, 'out_dy':out_dys,\n",
    "                             'submit_time':submit_time, 'queue':queue, 'gene_out_dy':gene_out_dy}, \n",
    "                            index=jnames)\n",
    "        jobs.ix[jobs.status != 'r', 'queue'] = np.nan\n",
    "        jobs.sort_values(by='submit_time', inplace=True)\n",
    "        return jobs\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_gene_status(jobs, out_dy):\n",
    "    fns = glob.glob(os.path.join(out_dy, 'gene_results', '*'))\n",
    "    exist = ['{}_{}'.format(os.path.split(x)[1], dy) for x in fns]\n",
    "    fns = glob.glob(os.path.join(out_dy, 'gene_results', '*', 'permuted_reml.tsv'))\n",
    "    finished = ['{}_{}'.format(x.split('/')[-2], dy) for x in fns]\n",
    "    finished = pd.DataFrame(True, columns=['gene_finished'], index=finished)\n",
    "    exist = pd.DataFrame(True, columns=['gene_exist'], index=exist)\n",
    "    if jobs is not None:\n",
    "        jobs = jobs.merge(finished, left_on='gene_out_dy', right_index=True, how='left')\n",
    "        jobs.ix[jobs.gene_finished.isnull(), 'gene_finished'] = False\n",
    "\n",
    "    gstatus = exist.join(finished, how='outer')\n",
    "    gstatus.ix[gstatus.gene_finished.isnull(), 'gene_finished'] = False\n",
    "    gstatus['job_running'] = False\n",
    "    if jobs is not None:\n",
    "        gstatus.ix[set(gstatus.index) & set(jobs.gene_out_dy), 'job_running'] = True\n",
    "    return jobs, gstatus\n",
    "\n",
    "def submit_jobs(\n",
    "    todo, \n",
    "    num_to_submit, \n",
    "    out_dy, \n",
    "    res_dys=None, \n",
    "    submit_failed=True, \n",
    "    queue=None,\n",
    "    ncores=4,\n",
    "    mem=16,\n",
    "    samples=os.path.join(ciepy.root, 'output', 'eqtl_input', 'emmax_samples.tsv'),\n",
    "    cov=os.path.join(ciepy.root, 'output', 'eqtl_input', 'emmax_sex_only.tsv'),\n",
    "    exp=os.path.join(ciepy.root, 'output', 'eqtl_input', 'tpm_log_filtered_phe_std_norm_peer_resid.tsv'),\n",
    "    min_perm=1000,\n",
    "    max_perm=10000,\n",
    "):\n",
    "    \"\"\"out_dy is the otuput directory where the per-gene output directories\n",
    "    will be stored. If failed == True, re-submit failed jobs.\"\"\"\n",
    "    # Set up output directories\n",
    "    cpy.makedir(os.path.join(out_dy, 'gene_results'))\n",
    "    cpy.makedir(os.path.join(out_dy, 'sge_scripts'))\n",
    "    cpy.makedir(os.path.join(out_dy, 'logs'))\n",
    "    # Get current jobs and gene statuses.\n",
    "    jobs = get_jobs()\n",
    "    jobs, gstatus = get_gene_status(jobs, out_dy)\n",
    "    exist = glob.glob(os.path.join(out_dy, 'gene_results', '*'))\n",
    "    # Find failed genes, clean them up, and resubmit if desired.\n",
    "    failed = gstatus[(gstatus.gene_finished == False) & (gstatus.job_running == False)]\n",
    "    failed = failed.ix[[x for x in failed.index if os.path.split(out_dy)[1] in x]]\n",
    "    if failed.shape[0] > 0:\n",
    "        failed_genes = [x.split('_')[0] for x in failed.index]\n",
    "        process_failed(failed_genes, out_dy)\n",
    "    if submit_failed:\n",
    "        submit_failed_genes(out_dy, exist)\n",
    "    # Don't submit genes whose output directory already exists.\n",
    "    exist = set([os.path.split(x)[1] for x in exist])\n",
    "    todo = set(todo) - exist\n",
    "    # Remove failed genes from list to submit.\n",
    "    failed_fn = os.path.join(out_dy, 'failed.tsv')\n",
    "    if os.path.exists(failed_fn):\n",
    "        failed = pd.read_table(failed_fn, squeeze=True, \n",
    "                               header=None, index_col=0)\n",
    "        todo = list(set(todo) - set(failed.index))\n",
    "\n",
    "    # Submit new jobs.\n",
    "    todo = list(todo)\n",
    "    ind = 0\n",
    "    while (ind < num_to_submit) and (ind < len(todo)):\n",
    "        # Get prior results to use as covariate if needed.\n",
    "        if res_dys:\n",
    "            res_files = []\n",
    "            for dy in res_dys:\n",
    "                if os.path.exists(os.path.join(dy, 'gene_results', todo[ind])):\n",
    "                    res_files.append(os.path.join(dy, 'gene_results', todo[ind], todo[ind] + '.tsv'))\n",
    "        else:\n",
    "            res_files = None\n",
    "        run_emmax_sge(todo[ind], out_dy, queue=queue, res_files=res_files, ncores=ncores,\n",
    "                      mem=mem, samples=samples, cov=cov, exp=exp, min_perm=min_perm, max_perm=max_perm)\n",
    "        ind += 1\n",
    "\n",
    "def submit_failed_genes(out_dy, exist):\n",
    "    # Submit failed genes with more memory.\n",
    "    failed_fn = os.path.join(out_dy, 'failed.tsv')\n",
    "    if os.path.exists(failed_fn):\n",
    "        failed = pd.read_table(failed_fn, index_col=0, \n",
    "                               header=None, squeeze=True)\n",
    "        todo = list(set(failed.index) - set([os.path.split(x)[1] for x in exist]))\n",
    "        for gene in todo:\n",
    "            mem = (failed[gene] + 1) * 16\n",
    "            run_emmax_sge(gene, out_dy, mem=mem)\n",
    "\n",
    "def process_failed(failed_genes, out_dy):\n",
    "    # Compare new failed genes to file (if it exists) and write to file.\n",
    "    # The file keeps track of how many times a gene has failed so we can boost\n",
    "    # the memory appropriately.\n",
    "    failed_fn = os.path.join(out_dy, 'failed.tsv')\n",
    "    if os.path.exists(failed_fn):\n",
    "        failed = pd.read_table(failed_fn, squeeze=True, \n",
    "                               header=None, index_col=0)\n",
    "        if len(set(failed.index) & set(failed_genes)) > 0:\n",
    "            failed[list(set(failed.index) & set(failed_genes))] += 1\n",
    "        t = pd.Series(1, index=list(set(failed_genes) - set(failed.index)))\n",
    "        failed = pd.concat([t, failed])\n",
    "    else:\n",
    "        failed = pd.Series(1, index=failed_genes)\n",
    "    failed.to_csv(failed_fn, header=None, sep='\\t')\n",
    "\n",
    "    # Remove output directories.\n",
    "    dys = [os.path.join(out_dy, 'gene_results', g) for g in failed_genes]\n",
    "    c = ' ; '.join(['if [ -d \"{0}\" ]; then rm -r {0} ; fi'.format(dy) for dy in dys])\n",
    "    subprocess.check_call(c, shell=True)\n",
    "\n",
    "    # Delete temp directories if they exist.\n",
    "    dys = ['/dev/shm/{}'.format(g) for g in failed_genes]\n",
    "    s = ' ; '.join(['if [ -d \"{0}\" ]; then rm -r {0} ; fi'.format(dy) for dy in dys])\n",
    "    c = 'pdsh -g n \"{}\"'.format(s)\n",
    "    subprocess.check_call(c, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def status(out_dy):\n",
    "    jobs = get_jobs()\n",
    "    jobs,gstatus = get_gene_status(jobs, out_dy)\n",
    "    jobs['job_name'] = jobs.index\n",
    "    jobs.index = jobs.gene_out_dy\n",
    "    print(pd.crosstab(gstatus.gene_finished, gstatus.job_running))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_dy = os.path.join(private_outdir, 'eqtls01')\n",
    "with open(os.path.join(ciepy.root, 'output', 'eqtl_input', 'eqtl_genes.tsv')) as f:\n",
    "    todo = [x.strip() for x in f.readlines()]\n",
    "res_dys = None\n",
    "\n",
    "num_to_submit = 4000\n",
    "submit_jobs(todo, num_to_submit, out_dy, res_dys=res_dys, submit_failed=True, queue=None)\n",
    "num_to_submit = 5000\n",
    "submit_jobs(todo, num_to_submit, out_dy, res_dys=res_dys, submit_failed=True, queue='opt', mem=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_running    False\n",
      "gene_finished       \n",
      "False           5619\n",
      "True            3383\n"
     ]
    }
   ],
   "source": [
    "status(out_dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-2b0d43f017d6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-14-2b0d43f017d6>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    2 +\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "2 + "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qvalues = pd.read_table(os.path.join(ciepy.root, 'output', 'eqtl_processing', 'eqtls01',\n",
    "                                     'qvalues.tsv'), index_col=0)\n",
    "sig = qvalues[qvalues.perm_sig]\n",
    "out_dy = os.path.join(private_outdir, 'eqtls02')\n",
    "res_dys = [os.path.join(private_outdir, 'eqtls01')]\n",
    "cpy.makedir(out_dy)\n",
    "todo = list(set(sig.index))\n",
    "\n",
    "num_to_submit = 10\n",
    "submit_jobs(todo, num_to_submit, out_dy, res_dys=res_dys, submit_failed=True, queue=None)\n",
    "num_to_submit = 5\n",
    "submit_jobs(todo, num_to_submit, out_dy, res_dys=res_dys, submit_failed=True, queue='opt', mem=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-426-9371e255fe97>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-426-9371e255fe97>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    2 +\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "2 +"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qvalues = pd.read_table(os.path.join(ciepy.root, 'output', 'eqtl_processing', 'eqtls02',\n",
    "                                     'qvalues.tsv'), index_col=0)\n",
    "sig = qvalues[qvalues.perm_sig]\n",
    "out_dy = os.path.join(private_outdir, 'eqtls03')\n",
    "res_dys = [os.path.join(private_outdir, 'eqtls01'), os.path.join(private_outdir, 'eqtls02')]\n",
    "cpy.makedir(out_dy)\n",
    "todo = list(set(sig.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(out_dy, '*'))]))\n",
    "\n",
    "num_to_submit = 327\n",
    "submit_jobs(todo, num_to_submit, out_dy, res_dys=res_dys, submit_failed=True, queue=None)\n",
    "num_to_submit = 218\n",
    "submit_jobs(todo, num_to_submit, out_dy, res_dys=res_dys, submit_failed=True, queue='opt', mem=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_running    False\n",
      "gene_finished       \n",
      "False              4\n",
      "True             569\n"
     ]
    }
   ],
   "source": [
    "status(out_dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-422-4715fb1d5390>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-422-4715fb1d5390>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    3 +\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "3 + "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qvalues = pd.read_table(os.path.join(ciepy.root, 'output', 'eqtl_processing', 'eqtls03',\n",
    "                                     'qvalues.tsv'), index_col=0)\n",
    "sig = qvalues[qvalues.perm_sig]\n",
    "out_dy = os.path.join(private_outdir, 'eqtls04')\n",
    "res_dys = [os.path.join(private_outdir, 'eqtls01'), os.path.join(private_outdir, 'eqtls02'),\n",
    "           os.path.join(private_outdir, 'eqtls02')]\n",
    "cpy.makedir(out_dy)\n",
    "todo = list(set(sig.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(out_dy, '*'))]))\n",
    "\n",
    "num_to_submit = 60\n",
    "submit_jobs(todo, num_to_submit, out_dy, res_dys=res_dys, submit_failed=True, queue=None)\n",
    "num_to_submit = 51\n",
    "submit_jobs(todo, num_to_submit, out_dy, res_dys=res_dys, submit_failed=True, queue='opt', mem=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2 + "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No PEER residuals, just covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_dy = out_dy = os.path.join(private_outdir, 'no_peer01')\n",
    "cpy.makedir(out_dy)\n",
    "\n",
    "todo = list(set(exp.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(out_dy, '*'))]))\n",
    "todo = [x for x in todo if gene_info.ix[x, 'chrom'] not in ['chrX', 'chrY', 'chrM']]\n",
    "\n",
    "cov_fn = os.path.join(ciepy.root, 'output', 'eqtl_input', 'emmax_full.tsv')\n",
    "exp_fn = os.path.join(ciepy.root, 'output', 'eqtl_input', 'tpm_log_filtered_phe_std_norm.tsv')\n",
    "\n",
    "num_to_submit = len(todo)\n",
    "submit_jobs(todo, num_to_submit, out_dy, submit_failed=True, \n",
    "            queue='opt', cov=cov_fn, exp=exp_fn, min_perm=0, max_perm=0, ncores=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unrelated individuals\n",
    "\n",
    "I want to run the analysis using unrelated individuals so I can do a power\n",
    "analysis. I also want to run with subsets of people to see how my power increases with sample\n",
    "size. I'll start with 40 and go in steps of 10 up to the full amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = os.path.join(ciepy.root, 'output', 'eqtl_input', 'unrelated_subsets.tsv')\n",
    "subsets = pd.read_table(fn, index_col=0, header=None, squeeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 40\n",
    "samples = sorted(subsets[i].split(','))\n",
    "out_dy = out_dy = os.path.join(private_outdir, 'unrelated_eqtls_{}'.format(i))\n",
    "cpy.makedir(out_dy)\n",
    "samples_fn = os.path.join(out_dy, 'samples.tsv')\n",
    "with open(samples_fn, 'w') as f:\n",
    "    f.write('\\n'.join(samples) + '\\n')\n",
    "    \n",
    "todo = list(set(exp.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(out_dy, '*'))]))\n",
    "todo = [x for x in todo if gene_info.ix[x, 'chrom'] not in ['chrX', 'chrY', 'chrM']]\n",
    "\n",
    "num_to_submit = 10\n",
    "submit_jobs(todo, num_to_submit, out_dy, submit_failed=True, \n",
    "            queue=None, samples=samples_fn, min_perm=0, max_perm=0, ncores=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2 + "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 50\n",
    "samples = sorted(subsets[i].split(','))\n",
    "out_dy = out_dy = os.path.join(private_outdir, 'unrelated_eqtls_{}'.format(i))\n",
    "cpy.makedir(out_dy)\n",
    "samples_fn = os.path.join(out_dy, 'samples.tsv')\n",
    "with open(samples_fn, 'w') as f:\n",
    "    f.write('\\n'.join(samples) + '\\n')\n",
    "    \n",
    "todo = list(set(exp.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(out_dy, '*'))]))\n",
    "todo = [x for x in todo if gene_info.ix[x, 'chrom'] not in ['chrX', 'chrY', 'chrM']]\n",
    "\n",
    "num_to_submit = len(todo)\n",
    "submit_jobs(todo, num_to_submit, out_dy, submit_failed=True, \n",
    "            queue=None, samples=samples_fn, min_perm=0, max_perm=0, ncores=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-33-2b0d43f017d6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-33-2b0d43f017d6>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    2 +\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "2 + "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 60\n",
    "samples = sorted(subsets[i].split(','))\n",
    "out_dy = out_dy = os.path.join(private_outdir, 'unrelated_eqtls_{}'.format(i))\n",
    "cpy.makedir(out_dy)\n",
    "samples_fn = os.path.join(out_dy, 'samples.tsv')\n",
    "with open(samples_fn, 'w') as f:\n",
    "    f.write('\\n'.join(samples) + '\\n')\n",
    "    \n",
    "todo = list(set(exp.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(out_dy, '*'))]))\n",
    "todo = [x for x in todo if gene_info.ix[x, 'chrom'] not in ['chrX', 'chrY', 'chrM']]\n",
    "\n",
    "num_to_submit = len(todo)\n",
    "submit_jobs(todo, num_to_submit, out_dy, submit_failed=True, \n",
    "            queue=None, samples=samples_fn, min_perm=0, max_perm=0, ncores=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2 + "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 70\n",
    "samples = sorted(subsets[i].split(','))\n",
    "out_dy = out_dy = os.path.join(private_outdir, 'unrelated_eqtls_{}'.format(i))\n",
    "cpy.makedir(out_dy)\n",
    "samples_fn = os.path.join(out_dy, 'samples.tsv')\n",
    "with open(samples_fn, 'w') as f:\n",
    "    f.write('\\n'.join(samples) + '\\n')\n",
    "    \n",
    "todo = list(set(exp.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(out_dy, '*'))]))\n",
    "todo = [x for x in todo if gene_info.ix[x, 'chrom'] not in ['chrX', 'chrY', 'chrM']]\n",
    "\n",
    "num_to_submit = len(todo)\n",
    "submit_jobs(todo, num_to_submit, out_dy, submit_failed=True, \n",
    "            queue=None, samples=samples_fn, min_perm=0, max_perm=0, ncores=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2 + "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 80\n",
    "samples = sorted(subsets[i].split(','))\n",
    "out_dy = out_dy = os.path.join(private_outdir, 'unrelated_eqtls_{}'.format(i))\n",
    "cpy.makedir(out_dy)\n",
    "samples_fn = os.path.join(out_dy, 'samples.tsv')\n",
    "with open(samples_fn, 'w') as f:\n",
    "    f.write('\\n'.join(samples) + '\\n')\n",
    "    \n",
    "todo = list(set(exp.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(out_dy, '*'))]))\n",
    "todo = [x for x in todo if gene_info.ix[x, 'chrom'] not in ['chrX', 'chrY', 'chrM']]\n",
    "\n",
    "num_to_submit = len(todo)\n",
    "submit_jobs(todo, num_to_submit, out_dy, submit_failed=True, \n",
    "            queue=None, samples=samples_fn, min_perm=0, max_perm=0, ncores=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2 + "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 90\n",
    "samples = sorted(subsets[i].split(','))\n",
    "out_dy = out_dy = os.path.join(private_outdir, 'unrelated_eqtls_{}'.format(i))\n",
    "cpy.makedir(out_dy)\n",
    "samples_fn = os.path.join(out_dy, 'samples.tsv')\n",
    "with open(samples_fn, 'w') as f:\n",
    "    f.write('\\n'.join(samples) + '\\n')\n",
    "    \n",
    "todo = list(set(exp.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(out_dy, '*'))]))\n",
    "todo = [x for x in todo if gene_info.ix[x, 'chrom'] not in ['chrX', 'chrY', 'chrM']]\n",
    "\n",
    "num_to_submit = len(todo)\n",
    "submit_jobs(todo, num_to_submit, out_dy, submit_failed=True, \n",
    "            queue=None, samples=samples_fn, min_perm=0, max_perm=0, ncores=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2 + "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 100\n",
    "samples = sorted(subsets[i].split(','))\n",
    "out_dy = out_dy = os.path.join(private_outdir, 'unrelated_eqtls_{}'.format(i))\n",
    "cpy.makedir(out_dy)\n",
    "samples_fn = os.path.join(out_dy, 'samples.tsv')\n",
    "with open(samples_fn, 'w') as f:\n",
    "    f.write('\\n'.join(samples) + '\\n')\n",
    "    \n",
    "todo = list(set(exp.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(out_dy, '*'))]))\n",
    "todo = [x for x in todo if gene_info.ix[x, 'chrom'] not in ['chrX', 'chrY', 'chrM']]\n",
    "\n",
    "num_to_submit = len(todo)\n",
    "submit_jobs(todo, num_to_submit, out_dy, submit_failed=True, \n",
    "            queue=None, samples=samples_fn, min_perm=0, max_perm=0, ncores=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2 + "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 110\n",
    "samples = sorted(subsets[i].split(','))\n",
    "out_dy = out_dy = os.path.join(private_outdir, 'unrelated_eqtls_{}'.format(i))\n",
    "cpy.makedir(out_dy)\n",
    "samples_fn = os.path.join(out_dy, 'samples.tsv')\n",
    "with open(samples_fn, 'w') as f:\n",
    "    f.write('\\n'.join(samples) + '\\n')\n",
    "    \n",
    "todo = list(set(exp.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(out_dy, '*'))]))\n",
    "todo = [x for x in todo if gene_info.ix[x, 'chrom'] not in ['chrX', 'chrY', 'chrM']]\n",
    "\n",
    "num_to_submit = len(todo)\n",
    "submit_jobs(todo, num_to_submit, out_dy, submit_failed=True, \n",
    "            queue=None, samples=samples_fn, min_perm=0, max_perm=0, ncores=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2 + "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
