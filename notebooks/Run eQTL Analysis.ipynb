{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run eQTL Analysis\n",
    "\n",
    "This notebook coordinates and executes the eQTL analysis. This notebook is\n",
    "specialized for the Frazer lab cluster. Since running the entire analysis is \n",
    "time consuming, I generally run it \"by hand,\" starting jobs for groups of\n",
    "genes at different times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/frazer01/home/cdeboever/software/anaconda/envs/cie/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import cPickle\n",
    "import datetime\n",
    "import glob\n",
    "import gzip\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "import cdpybio as cpb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pybedtools as pbt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import cardipspy as cpy\n",
    "import ciepy\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "random.seed(20150605)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outdir = os.path.join(ciepy.root, 'output',\n",
    "                      'run_eqtl_analysis')\n",
    "cpy.makedir(outdir)\n",
    "\n",
    "private_outdir = os.path.join(ciepy.root, 'private_output',\n",
    "                              'run_eqtl_analysis')\n",
    "cpy.makedir(private_outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gene_info = pd.read_table(cpy.gencode_gene_info, index_col=0)\n",
    "\n",
    "fn = os.path.join(ciepy.root, 'output', 'eqtl_input', 'gene_to_regions.p')\n",
    "gene_to_regions = cPickle.load(open(fn, 'rb'))\n",
    "\n",
    "exp = pd.read_table(os.path.join(ciepy.root, 'output', 'eqtl_input', \n",
    "                                 'tpm_log_filtered_phe_std_norm_peer_resid.tsv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_emmax(gene_id):\n",
    "    os.chdir('/raid3/projects/CARDIPS/analysis/cardips-ipsc-eqtl/notebooks')\n",
    "    toutdir = os.path.join(outdir, 'results', gene_id)\n",
    "    if not os.path.exists(toutdir):\n",
    "        cpy.makedir(toutdir)\n",
    "        fn = os.path.join(toutdir, '{}.sh'.format(gene_id))\n",
    "        with open(fn, 'w') as f:\n",
    "            c = 'python {} \\\\\\n\\t'.format(os.path.join(ciepy.root, 'scripts', 'run_emmax.py'))\n",
    "            c += ' \\\\\\n\\t'.join([\n",
    "                    gene_id,\n",
    "                    os.path.join(ciepy.root, 'private_data', 'wgs', 'biallelic_snvs.vcf.gz'),\n",
    "                    ','.join(gene_to_regions[gene_id]),\n",
    "                    os.path.join(ciepy.root, 'output', 'eqtl_input', \n",
    "                                 'tpm_log_filtered_phe_std_norm_peer_resid.tsv'),\n",
    "                    os.path.join(ciepy.root, 'output', 'eqtl_input', 'emmax.ind'),\n",
    "                    os.path.join(ciepy.root, 'output', 'eqtl_input', 'wgs.kin'),\n",
    "                    toutdir,\n",
    "                    '-c {}'.format(os.path.join(ciepy.root, 'output', 'eqtl_input', \n",
    "                                                'emmax_sex_only.cov')),\n",
    "                ])\n",
    "            f.write(c + '\\n')\n",
    "        subprocess.check_call('bash {}'.format(fn), shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGE\n",
    "\n",
    "Run jobs using SGE queue system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_emmax_sge(gene_ids, n=10):\n",
    "    \"\"\"\n",
    "    gene_ids is a list of gene_ids and n is the number of genes to submit at the same time.\n",
    "    This script will find n number of genes that EMMAX hasn't been run for and submit a job\n",
    "    for those genes.\n",
    "    \"\"\"\n",
    "    genes_todo = []\n",
    "    i = 0\n",
    "    while len(genes_todo) < n:\n",
    "        if not os.path.exists(os.path.join(outdir, 'results', gene_ids[i])):\n",
    "            genes_todo.append(gene_ids[i])\n",
    "        i += 1\n",
    "    res = datetime.datetime.now()\n",
    "    #date = '{}-{:02d}-{:02d}-{:02d}-{:02d}-{:02d}'.format(res.year, res.month,\n",
    "    #                                                      res.day, res.hour,\n",
    "    #                                                      res.minute,\n",
    "    #                                                      res.second)\n",
    "    date = re.sub(r'\\D', '_', str(res))\n",
    "    fn = os.path.join(outdir, 'results', 'sge_scripts', '{}.sh'.format(date))\n",
    "    with open(fn, 'w') as f:\n",
    "        f.write('#!/bin/bash\\n\\n')\n",
    "        f.write('#$ -N emmax_{}\\n'.format(date))\n",
    "        f.write('#$ -l h_vmem=8G\\n')\n",
    "        f.write('#$ -pe smp 1\\n')\n",
    "        f.write('#$ -S /bin/bash\\n')\n",
    "        f.write('#$ -o {}/emmax_{}.out\\n'.format(\n",
    "                os.path.join(outdir, 'results', 'sge_scripts'), date))\n",
    "        f.write('#$ -e {}/emmax_{}.err\\n\\n'.format(\n",
    "                    os.path.join(outdir, 'results', 'sge_scripts'), date))\n",
    "        f.write('module load cardips\\n')\n",
    "        f.write('source activate cie\\n\\n')\n",
    "        for gene_id in genes_todo:\n",
    "            toutdir = os.path.join(outdir, 'results', gene_id)\n",
    "            cpy.makedir(toutdir)\n",
    "            c = 'python {} \\\\\\n\\t'.format(os.path.join(ciepy.root, 'scripts', 'run_emmax.py'))\n",
    "            c += ' \\\\\\n\\t'.join([\n",
    "                    gene_id,\n",
    "                    os.path.join(ciepy.root, 'private_output/eqtl_input/filtered_all/0000.vcf.gz'),\n",
    "                    ','.join([x[3:] for x in gene_to_regions[gene_id]]),\n",
    "                    os.path.join(ciepy.root, 'output', 'eqtl_input', \n",
    "                                 'tpm_log_filtered_phe_std_norm_peer_resid.tsv'),\n",
    "                    os.path.join(ciepy.root, 'output', 'eqtl_input', 'emmax.ind'),\n",
    "                    os.path.join(ciepy.root, 'output', 'eqtl_input', 'wgs.kin'),\n",
    "                    toutdir,\n",
    "                    '-c {}'.format(os.path.join(ciepy.root, 'output', 'eqtl_input', \n",
    "                                                'emmax_sex_only.cov')),\n",
    "                ])\n",
    "            f.write(c + '\\n\\n')\n",
    "    subprocess.check_call('qsub {}'.format(fn), shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cpy.makedir(os.path.join(outdir, 'results', 'sge_scripts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "todo = list(set(exp.index) - \n",
    "            set([os.path.split(x)[1] for x in glob.glob(os.path.join(outdir, 'results', '*'))]))\n",
    "todo = [x for x in todo if gene_info.ix[x, 'chrom'] not in ['chrX', 'chrY', 'chrM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove failed genes. I'll wait to resubmit these with more memory.\n",
    "if os.path.exists(os.path.join(outdir, 'failed.txt')):\n",
    "    with open(os.path.join(outdir, 'failed.txt')) as f:\n",
    "        failed = [x.strip() for x in f.readlines()]\n",
    "todo = list(set(todo) - set(failed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(todo) > 0:\n",
    "    for i in range(10):\n",
    "        for j in range(20):\n",
    "            run_emmax_sge(todo, n=5)\n",
    "        time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for failed jobs\n",
    "\n",
    "Some genes have errors when they are running. This can happen if I don't request enough memory \n",
    "for instance. If a job fails on a given gene, any of the genes after that one in that job also\n",
    "aren't analyzed. These genes won't have `minimum_pvalues.tsv` files even when their job finishes. \n",
    "I want to identify these genes and remove their output\n",
    "directory so they will be run in a new job. I think these genes often leave behind their\n",
    "temp directory so I'll have to go delete those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>job_status</th>\n",
       "      <th>finished</th>\n",
       "      <th>running</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>complete</th>\n",
       "      <td>1181</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incomplete</th>\n",
       "      <td>11</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "job_status  finished  running\n",
       "status                       \n",
       "complete        1181      348\n",
       "incomplete        11      897"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get jobs currently waiting to start or started.\n",
    "running = !qstat -r | grep jobname\n",
    "running = [x.split()[-1] for x in running if 'emmax_' in x]\n",
    "# Get all submission scripts created.\n",
    "fns = glob.glob(os.path.join(outdir, 'results', 'sge_scripts', '*.sh'))\n",
    "jobnames = []\n",
    "genes = []\n",
    "for fn in fns:\n",
    "    with open(fn) as f:\n",
    "        lines = [x.strip() for x in f.readlines()]\n",
    "    genes.append([x.split()[0] for x in lines if x[0:4] == 'ENSG'])\n",
    "    jobnames.append(lines[2].split()[-1])\n",
    "jobs = pd.DataFrame(np.array(fns).T, index=jobnames, columns=['path'])\n",
    "jobs = pd.DataFrame([fns, genes], columns=jobnames, index=['path', 'genes']).T\n",
    "jobs['status'] = 'finished'\n",
    "# For now, running means either the job is waiting to start or has started.\n",
    "jobs.ix[running, 'status'] = 'running'\n",
    "\n",
    "genes = [os.path.split(x)[1] for x in glob.glob(os.path.join(outdir, 'results', 'ENSG*'))]\n",
    "genes = pd.DataFrame(index=genes)\n",
    "genes['status'] = 'incomplete'\n",
    "min_pvals = glob.glob(os.path.join(outdir, 'results', 'ENSG*', 'minimum_pvalues.tsv'))\n",
    "genes.ix[[x.split('/')[-2] for x in min_pvals], 'status'] = 'complete'\n",
    "genes['job_status'] = 'finished'\n",
    "# If there is any running job with this gene, we want to mark the job_status\n",
    "# as running.\n",
    "running_genes = [item for sublist in jobs.ix[jobs.status == 'running', 'genes'].values \n",
    "                 for item in sublist]\n",
    "genes.ix[running_genes, 'job_status'] = 'running'\n",
    "\n",
    "pd.crosstab(genes.status, genes.job_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any genes that incomplete but whose jobs are finished had errors. I need \n",
    "to delete their temp directories and the output directories and try resubmitting.\n",
    "I may want to resubmit with more memory. I'll keep track of the failed genes so\n",
    "I can wait to resubmit them with more memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for g in genes[(genes.status == 'incomplete') & (genes.job_status == 'finished')].index:\n",
    "    # Delete temp directory if it exists.\n",
    "    dy = '/dev/shm/{}'.format(g)\n",
    "    c = 'pdsh -g n \"if [ -d \"{0}\" ]; then rm -r {0} ; fi\"'.format(dy)\n",
    "    subprocess.check_call(c, shell=True)\n",
    "\n",
    "    # Remove output directory. \n",
    "    dy = os.path.join(outdir, 'results', g)\n",
    "    c = 'rm -r {}'.format(dy)\n",
    "    subprocess.check_call(c, shell=True)\n",
    "with open(os.path.join(outdir, 'failed.txt'), 'a') as f:\n",
    "    f.write('\\n'.join(genes[(genes.status == 'incomplete') & (genes.job_status == 'finished')].index) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chr3:52154037-54164478']"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_to_regions['ENSG00000163933.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "3 +"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory requirement\n",
    "\n",
    "I have to specify the amount of memory needed for each job. I think I can get\n",
    "away with one thread but the amount of memory scales with the number of variants\n",
    "(I'm guessing) so I need to figure out the relationship between number of variants\n",
    "and the amount of RAM needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
