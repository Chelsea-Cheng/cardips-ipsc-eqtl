{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import urllib2\n",
    "\n",
    "import cdpybio as cpb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import pybedtools as pbt\n",
    "import seaborn as sns\n",
    "import vcf as pyvcf\n",
    "\n",
    "import cardipspy as cpy\n",
    "import ciepy\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "dy_name = '3d_structure'\n",
    "\n",
    "import socket\n",
    "if socket.gethostname() == 'fl-hn1' or socket.gethostname() == 'fl-hn2':\n",
    "    dy = os.path.join(ciepy.root, 'sandbox', 'tmp', dy_name)\n",
    "    cpy.makedir(dy)\n",
    "    pbt.set_tempdir(dy)\n",
    "    \n",
    "outdir = os.path.join(ciepy.root, 'output', dy_name)\n",
    "cpy.makedir(outdir)\n",
    "\n",
    "private_outdir = os.path.join(ciepy.root, 'private_output', dy_name)\n",
    "cpy.makedir(private_outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tg = pd.read_table(cpy.gencode_transcript_gene, index_col=0, \n",
    "                   header=None, squeeze=True)\n",
    "gene_info = pd.read_table(cpy.gencode_gene_info, index_col=0)\n",
    "fn = os.path.join(ciepy.root, 'output', 'eqtl_input', \n",
    "                  'tpm_log_filtered_phe_std_norm_peer_resid.tsv')\n",
    "exp = pd.read_table(fn, index_col=0)\n",
    "\n",
    "genes = pbt.BedTool(cpy.gencode_gene_bed)\n",
    "\n",
    "t_to_g = pd.read_table(cpy.gencode_transcript_gene, index_col=0, header=None, squeeze=True)\n",
    "\n",
    "fn = os.path.join(os.path.split(cpy.roadmap_15_state_annotation)[0], 'EIDlegend.txt')\n",
    "roadmap_ids = pd.read_table(fn, squeeze=True, index_col=0, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TADs\n",
    "\n",
    "I'd like to look for enrichment of eQTLs in TADs. As in the Grubert et al. 2015 paper, I\n",
    "can mirror the position of the variant over the gene and see whether they fall within the\n",
    "same TAD as often. They also shuffled the locations of the TADs and compared the number of\n",
    "distal (> 50 kb) QTLs falling within the same TAD as the gene against the shuffled data.\n",
    "I can do the same analysis using sets of null variants as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download TADs from Dixon et al. 2012. These coordinates are in hg18 so we'll download the\n",
    "# liftOver chain files and convert the bed file.\n",
    "\n",
    "dy = os.path.join(private_outdir, 'hESC')\n",
    "if not os.path.exists(dy):\n",
    "    out = os.path.join(private_outdir, 'hESC.domain.tar.gz')\n",
    "    !curl http://132.239.201.216/mouse/hi-c/hESC.domain.tar.gz > {out}\n",
    "    !tar -C {private_outdir} -xvf {out}\n",
    "    !rm {out}\n",
    "    \n",
    "fn = os.path.join(private_outdir, 'hg18ToHg19.over.chain')\n",
    "if not os.path.exists(fn):\n",
    "    url = ('http://hgdownload.cse.ucsc.edu/goldenPath/hg18/liftOver/hg18ToHg19.over.chain.gz')\n",
    "    !curl {url} | zcat > {fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in TADs, convert to hg19.\n",
    "tads = pbt.BedTool(os.path.join(private_outdir, 'hESC', 'combined', 'total.combined.domain'))\n",
    "n = len(tads)\n",
    "mapped = os.path.join(outdir, 'hg19_hESC_tads_mapped.bed')\n",
    "unmapped = os.path.join(outdir, 'hg19_hESC_tads_unmapped.txt')\n",
    "tads = cpb.analysis.liftover_bed(tads, os.path.join(private_outdir, 'hg18ToHg19.over.chain'),\n",
    "                                 mapped, unmapped)\n",
    "print('Converted {} of {} TADs to hg19.'.format(len(tads), n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## [Tang et al. 2015](http://www.sciencedirect.com/science/article/pii/S0092867415015044)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annot_beds = dict()\n",
    "# H3K27ac\n",
    "fn = os.path.join(ciepy.root, 'output', 'ji_et_al_2015_processing', 'h3k27ac_peaks.bed')\n",
    "annot_beds['h3k27ac'] = pbt.BedTool(fn)\n",
    "# Genes\n",
    "annot_beds['gene'] = genes\n",
    "# Promoters\n",
    "promoters = pbt.BedTool('/publicdata/gencode_v19_20151104/promoters_by_gene.bed')\n",
    "df = promoters.to_dataframe()\n",
    "df.name = df.name.apply(lambda x: x.split('_')[0])\n",
    "s = '\\n'.join(df.astype(str).apply(lambda x: '\\t'.join(x), axis=1)) + '\\n'\n",
    "promoters = pbt.BedTool(s, from_string=True)\n",
    "annot_beds['promoter'] = promoters\n",
    "# TSS\n",
    "tss = pbt.BedTool(cpy.gencode_tss_bed)\n",
    "df = tss.to_dataframe()\n",
    "df.name = t_to_g[df.name.apply(lambda x: x.split('_')[0])].values\n",
    "df = df.drop_duplicates()\n",
    "s = '\\n'.join(df.astype(str).apply(lambda x: '\\t'.join(x), axis=1)) + '\\n'\n",
    "tss = pbt.BedTool(s, from_string=True)\n",
    "annot_beds['tss'] = tss\n",
    "# Exons\n",
    "exons = pbt.BedTool(cpy.gencode_exon_bed)\n",
    "df = exons.to_dataframe()\n",
    "df.name = t_to_g[df.name].values\n",
    "df = df.drop_duplicates()\n",
    "s = '\\n'.join(df.astype(str).apply(lambda x: '\\t'.join(x), axis=1)) + '\\n'\n",
    "exons = pbt.BedTool(s, from_string=True)\n",
    "annot_beds['exon'] = exons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_tang(url):\n",
    "    s = cpb.general.read_gzipped_text_url(url)\n",
    "    lines = [x.split() for x in s.strip().split('\\n')]\n",
    "    df = pd.DataFrame(lines, columns=['chrom1', 'start1', 'end1', \n",
    "                                      'chrom2', 'start2', 'end2', 'freq'])\n",
    "    df.index = df.chrom1 + ':' + df.start1 + '-' + df.end1 + '==' + df.chrom2 + ':' + df.start1 + '-' + df.end2\n",
    "    for c in ['start1', 'start2', 'end1', 'end2', 'freq']:\n",
    "        df[c] = df[c].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "class AnnotatedBed:\n",
    "    def __init__(\n",
    "        self,   \n",
    "        bed,\n",
    "        annot_beds,\n",
    "        completely_contains=None,\n",
    "    ):  \n",
    "        \"\"\"\n",
    "        Initialize AnnotatedBed object.\n",
    "            \n",
    "        Parameters\n",
    "        ----------\n",
    "        bed : str or pybedtools.Bedtool\n",
    "            Bed file to annotate.\n",
    "        \n",
    "        annot_beds : dict\n",
    "            Dict whose keys are names (like 'gene', 'promoter', etc.) and whose\n",
    "            values are bed files to annotate the input bed file with.\n",
    "            \n",
    "        completely_contains : list\n",
    "            List of keys from annot_beds. For these beds, we will check whether\n",
    "            the features is entirely contained by features \"bed.\"\n",
    "        \n",
    "        \"\"\"            \n",
    "        self._initialize_bt(bed)\n",
    "        self._num_cols = len(self.bt[0].fields)\n",
    "        self._has_name_col = self._num_cols > 3\n",
    "        self._initialize_dfs()\n",
    "        self._initialize_annot_beds(annot_beds)\n",
    "        for k in annot_beds.keys():\n",
    "            self.annotate_bed(self.bt, k, k)\n",
    "        for k in completely_contains:\n",
    "            self.annotate_bed(self.bt, k, k, complete=True)\n",
    "        self._bt_path = None\n",
    "            \n",
    "    def load_saved_bts(self):\n",
    "        \"\"\"If the AnnotatedBed object was saved to a pickle and reloaded,\n",
    "        this method remakes the BedTool object.\"\"\"\n",
    "        if self._bt_path:\n",
    "            self.bt = pbt.BedTool(self._bt_path)\n",
    "            \n",
    "    def save(\n",
    "        self,\n",
    "        path,\n",
    "        name,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Save AnnotatedBed object and bed file. The object is stored in a pickle\n",
    "        and the bed file is saved as a separate bed file. The object can be\n",
    "        reloaded by reading the pickle using cPickle.\n",
    "            \n",
    "        Parameters\n",
    "        ----------\n",
    "        path : str\n",
    "            Path to save files to. Path should include a basename for the files.\n",
    "            For instance, path='~/abc' will create files like ~/abc.pickle,\n",
    "            ~/abc.bed, etc.\n",
    "            \n",
    "        name : str\n",
    "            Descriptive name used for bed file trackline.\n",
    "        \"\"\"\n",
    "        t = 'track type=bed name=\"{}\"'.format(name)\n",
    "        self.bt.saveas(path + '.bed', trackline=t)\n",
    "        self._bt_path = path + '.bed'\n",
    "        import cPickle\n",
    "        cPickle.dump(self, open(path + '.pickle', 'w'))\n",
    "        \n",
    "    def _initialize_annot_beds(\n",
    "        self, \n",
    "        annot_beds,\n",
    "    ):\n",
    "        import pybedtools as pbt\n",
    "        self.annot_beds = dict()\n",
    "        for k in annot_beds.keys():\n",
    "            if type(annot_beds[k]) == str:\n",
    "                self.annot_beds[k] = pbt.BedTool(annot_beds[k])\n",
    "            else:\n",
    "                self.annot_beds[k] = annot_beds[k]\n",
    "\n",
    "    def _initialize_dfs(\n",
    "        self,\n",
    "    ):  \n",
    "        self.df = self.bt.to_dataframe()\n",
    "        if self._has_name_col:\n",
    "            if len(set(self.df.name)) != self.df.shape[0]:\n",
    "                self._has_name_col = False\n",
    "        if self._has_name_col:\n",
    "            self.df.index = self.df.name\n",
    "        else:\n",
    "            self.df.index = (self.df.chrom.astype + ':' +\n",
    "                             self.df.start.astype(str) + '-' +\n",
    "                             self.df.end.astype(str))\n",
    "        self.feature_to_df = pd.DataFrame(index=self.df.index)\n",
    "\n",
    "    def _initialize_bt(\n",
    "        self,\n",
    "        bed,           \n",
    "    ):                 \n",
    "        import pybedtools as pbt\n",
    "        if type(bed) == str:\n",
    "            self.bt = pbt.BedTool(bed)\n",
    "        else:\n",
    "            self.bt = bed\n",
    "        self.bt = self.bt.sort()\n",
    "        \n",
    "    def bt_from_df(self):\n",
    "        \"\"\"Make a BedTool object for the input bed file.\"\"\"\n",
    "        import pybedtools as pbt\n",
    "        s = ('\\n'.join(df.astype(str).apply(lambda x: '\\t'.join(x), axis=1)) +\n",
    "             '\\n')\n",
    "        df.bt = pbt.BedTool(s, from_string=True)\n",
    "        \n",
    "    def annotate_bed(\n",
    "        self,\n",
    "        bt,\n",
    "        name,\n",
    "        col_name,\n",
    "        complete=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Annotate the input bed file using one of the annotation beds.\n",
    "        Parameters\n",
    "        ----------\n",
    "        name : str\n",
    "            The key for the annoation bed file in annot_beds. \n",
    "        \n",
    "        col_name : str\n",
    "            Used to name the columns that will be made.\n",
    "        complete : bool\n",
    "            If True, this method will check whether the features in the\n",
    "            annotation bed are completely contained by the features in the input\n",
    "            bed.\n",
    "        \n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        has_name_col = len(self.annot_beds[name][0].fields) > 3\n",
    "        if complete:\n",
    "            res = bt.intersect(self.annot_beds[name], sorted=True, wo=True, F=1)\n",
    "            col_name = col_name + '_complete'\n",
    "        else:\n",
    "            res = bt.intersect(self.annot_beds[name], sorted=True, wo=True)\n",
    "        df = res.to_dataframe(names=range(len(res[0].fields)))\n",
    "        if self._has_name_col:\n",
    "            ind = df[3].values\n",
    "        else:\n",
    "            ind = list(df[0].astype(str) + ':' +\n",
    "                       df[1].astype(str) + '-' +\n",
    "                       df[2].astype(str))\n",
    "        if has_name_col:\n",
    "            vals = df[self._num_cols + 3].values\n",
    "        else:\n",
    "            vals = list(df[self._num_cols + 0].astype(str) + ':' +\n",
    "                        df[self._num_cols + 1].astype(str) + '-' +\n",
    "                        df[self._num_cols + 2].astype(str))\n",
    "        self.df[col_name] = False\n",
    "        self.df.ix[set(ind), col_name] = True\n",
    "        se = pd.Series(vals, index=ind)\n",
    "        vc = pd.Series(se.index).value_counts()\n",
    "        self.feature_to_df[col_name] = np.nan\n",
    "        self.feature_to_df.ix[list(vc[vc == 1].index), col_name] = \\\n",
    "                se[list(vc[vc == 1].index)].apply(lambda x: set([x]))\n",
    "        m = list(set(vc[vc > 1].index))\n",
    "        v = []\n",
    "        for i in m:\n",
    "            v.append(set(se[i].values))\n",
    "        self.feature_to_df.ix[m, col_name] = v\n",
    "        \n",
    "class AnnotatedInteractions:\n",
    "    def __init__(\n",
    "        self,   \n",
    "        df,\n",
    "        annot_beds,\n",
    "        completely_contains=None,\n",
    "    ):  \n",
    "        \"\"\"\n",
    "        Initialize AnnotatedInteractions object.\n",
    "            \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas.DataFrame\n",
    "            Dataframe with peaks. Must contain columns chrom1, start1, end1,\n",
    "            chrom2, start2, and end2. Other columns will not be removed but \n",
    "            may be overwritten if they clash with column names created here.\n",
    "            Interactions must be unique.\n",
    "        \n",
    "        annot_beds : dict\n",
    "            Dict whose keys are names (like 'gene', 'promoter', etc.) and whose\n",
    "            values are bed files to annotate the input bed file with.\n",
    "        \n",
    "        \"\"\"            \n",
    "        self.df = df.copy(deep=True)\n",
    "        self.df.index = (self.df.chrom1.astype(str) + ':' + self.df.start1.astype(str) + '-' + \n",
    "                         self.df.end1.astype(str) + '==' + self.df.chrom2.astype(str) + ':' + \n",
    "                         self.df.start1.astype(str) + '-' + self.df.end2.astype(str))\n",
    "        assert len(set(self.df.index)) == self.df.shape[0]\n",
    "        self.df['name'] = self.df.index\n",
    "        self.feature_to_df = pd.DataFrame(index=self.df.index)\n",
    "        self.annotate_interactions()\n",
    "        self.bts_from_df()\n",
    "        self._initialize_annot_beds(annot_beds)\n",
    "        for k in annot_beds.keys():\n",
    "            self.annotate_bed(bt=self.bt1, name=k, col_name='{}1'.format(k), df_col='anchor1')\n",
    "            if k in completely_contains:\n",
    "                self.annotate_bed(bt=self.bt1, name=k, col_name='{}1_complete'.format(k), df_col='anchor1', complete=True)\n",
    "        for k in annot_beds.keys():\n",
    "            self.annotate_bed(bt=self.bt2, name=k, col_name='{}2'.format(k), df_col='anchor2')\n",
    "            if k in completely_contains:\n",
    "                self.annotate_bed(bt=self.bt2, name=k, col_name='{}2_complete'.format(k), df_col='anchor2', complete=True)\n",
    "        for k in annot_beds.keys():\n",
    "            self.annotate_bed(bt=self.bt1, name=k, col_name='{}_loop'.format(k), df_col='loop')\n",
    "            if k in completely_contains:\n",
    "                self.annotate_bed(bt=self.bt1, name=k, col_name='{}_loop_complete'.format(k), df_col='loop', complete=True)\n",
    "        for k in annot_beds.keys():\n",
    "            self.annotate_bed(bt=self.bt1, name=k, col_name='{}_loop_inner'.format(k), df_col='loop_inner')\n",
    "            if k in completely_contains:\n",
    "                self.annotate_bed(bt=self.bt1, name=k, col_name='{}_loop_inner_complete'.format(k), \n",
    "                                  df_col='loop_inner', complete=True)\n",
    "        self._bt1_path = None\n",
    "        self._bt2_path = None\n",
    "        self._bt_loop_path = None\n",
    "        self._bt_loop_inner_path = None\n",
    "\n",
    "    def _initialize_annot_beds(\n",
    "        self, \n",
    "        annot_beds,\n",
    "    ):\n",
    "        import pybedtools as pbt\n",
    "        self.annot_beds = dict()\n",
    "        for k in annot_beds.keys():\n",
    "            if type(annot_beds[k]) == str:\n",
    "                self.annot_beds[k] = pbt.BedTool(annot_beds[k])\n",
    "            else:\n",
    "                self.annot_beds[k] = annot_beds[k]\n",
    "\n",
    "    def load_saved_bts(self):\n",
    "        \"\"\"If the AnnotatedInteractions object was saved to a pickle and\n",
    "        reloaded, this method remakes the BedTool objects.\"\"\"\n",
    "        if self._bt1_path:\n",
    "            self.bt1 = pbt.BedTool(self._bt1_path)\n",
    "        if self._bt2_path:\n",
    "            self.bt2 = pbt.BedTool(self._bt2_path)\n",
    "        if self._bt_loop_path:\n",
    "            self.bt_loop = pbt.BedTool(self._bt_loop_path)\n",
    "        if self._bt_loop_inner_path:\n",
    "            self.bt_loop_inner = pbt.BedTool(self._bt_loop_inner_path)\n",
    "        \n",
    "    def save(\n",
    "        self,\n",
    "        path,\n",
    "        name,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Save AnnotatedInteractions object and bed files. The object is stored in\n",
    "        a pickle and the bed files are saved as separate bed files. The object\n",
    "        can be reloaded by reading the pickle using cPickle and the BedTool\n",
    "        objects can be recreated using .load_saved_bts().\n",
    "            \n",
    "        Parameters\n",
    "        ----------\n",
    "        path : str\n",
    "            Path to save files to. Path should include a basename for the files.\n",
    "            For instance, path='~/abc' will create files like ~/abc.pickle,\n",
    "            ~/abc_anchor1.bed, etc.\n",
    "            \n",
    "        name : str\n",
    "            Descriptive name used for bed file trackline.\n",
    "        \"\"\"\n",
    "        t = 'track type=bed name=\"{}_anchor1\"'.format(name)\n",
    "        self.bt1.saveas(path + '_anchor1.bed', trackline=t)\n",
    "        self._bt1_path = path + '_anchor1.bed'\n",
    "        t = 'track type=bed name=\"{}_anchor2\"'.format(name)\n",
    "        self.bt2.saveas(path + '_anchor2.bed', trackline=t)\n",
    "        self._bt2_path = path + '_anchor2.bed'\n",
    "        t = 'track type=bed name=\"{}_loop\"'.format(name)\n",
    "        self.bt_loop.saveas(path + '_loop.bed', trackline=t)\n",
    "        self._bt_loop_path = path + '_loop.bed'\n",
    "        t = 'track type=bed name=\"{}_loop_inner\"'.format(name)\n",
    "        self.bt_loop_inner.saveas(path + '_loop_inner.bed', trackline=t)\n",
    "        self._bt_loop_inner_path = path + '_loop_inner.bed'\n",
    "        import cPickle\n",
    "        cPickle.dump(self, open(path + '.pickle', 'w'))   \n",
    "    \n",
    "    def annotate_bed(\n",
    "        self,\n",
    "        bt,\n",
    "        name,\n",
    "        col_name,\n",
    "        complete=None,\n",
    "        df_col=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Annotate the input bed file using one of the annotation beds.\n",
    "        Parameters\n",
    "        ----------\n",
    "        bt : pybedtools.BedTool\n",
    "            BedTool for either one of the anchors, the loops,\n",
    "            or the loop inners.\n",
    "        \n",
    "        name : str\n",
    "            The key for the annoation bed file in annot_beds. \n",
    "        \n",
    "        col_name : str\n",
    "            Used to name the columns that will be made.\n",
    "            \n",
    "        complete : bool\n",
    "            If True, this method will check whether the features in the\n",
    "            annotation bed are completely contained by the features in the input\n",
    "            bed.\n",
    "            \n",
    "        df_col : str\n",
    "            If the name for bt isn't the index of self.df, this specifies\n",
    "            which column of self.df contains the names for bt. For instance,\n",
    "            if bt is the anchor1 BedTool, the df_col='anchor11'.\n",
    "        \n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        has_name_col = len(self.annot_beds[name][0].fields) > 3\n",
    "        print('one')\n",
    "        if complete:\n",
    "            res = bt.intersect(self.annot_beds[name], sorted=True, wo=True, F=1)\n",
    "        else:\n",
    "            res = bt.intersect(self.annot_beds[name], sorted=True, wo=True)\n",
    "        print('two')\n",
    "        try:\n",
    "            df = res.to_dataframe(names=range(len(res[0].fields)))\n",
    "            ind = df[3].values\n",
    "            if df_col is None:\n",
    "                self.df[col_name] = False\n",
    "                self.df.ix[set(ind), col_name] = True\n",
    "            else:\n",
    "                tdf = pd.DataFrame(True, index=ind, columns=[col_name])\n",
    "                self.df = self.df.merge(tdf, left_on=df_col, right_index=True, how='outer')\n",
    "                self.df[col_name] = self.df[col_name].fillna(False)\n",
    "                #self.df.ix[self.df[col_name].isnull(), col_name] = False\n",
    "            print('a')\n",
    "            if has_name_col:\n",
    "                vals = df[7].values\n",
    "            else:\n",
    "                vals = list(df[4].astype(str) + ':' +\n",
    "                            df[5].astype(str) + '-' +\n",
    "                            df[6].astype(str))\n",
    "            print('b')\n",
    "            df.index = vals\n",
    "            gb = df.groupby(3)\n",
    "            t = pd.Series(gb.groups)\n",
    "            print('c')\n",
    "            t = pd.DataFrame(t.apply(lambda x: set(x)))\n",
    "            print('d')\n",
    "            t.columns = ['{}_features'.format(col_name)]\n",
    "            self.df = self.df.merge(t, left_on=df_col, right_index=True, how='outer')\n",
    "            print('e')\n",
    "        except IndexError:\n",
    "            pass\n",
    "        \n",
    "    def annotate_interactions(self):\n",
    "        import numpy as np\n",
    "        self.df['anchor1'] = (self.df.chrom1.astype(str) + ':' +\n",
    "                              self.df.start1.astype(str) + '-' +\n",
    "                              self.df.end1.astype(str))\n",
    "        self.df['anchor2'] = (self.df.chrom2.astype(str) + ':' +\n",
    "                              self.df.start2.astype(str) + '-' +\n",
    "                              self.df.end2.astype(str))\n",
    "        self.df['intra'] = True\n",
    "        self.df.ix[self.df.chrom1 != self.df.chrom2, 'intra'] = False\n",
    "        ind = self.df[self.df.intra].index\n",
    "        self.df['loop'] = np.nan\n",
    "        self.df.ix[ind, 'loop'] = (\n",
    "            self.df.ix[ind, 'chrom1'] + ':' + \n",
    "            self.df.ix[ind, ['start1', 'start2']].min(axis=1).astype(str) + \n",
    "            '-' + self.df.ix[ind, ['end1', 'end2']].max(axis=1).astype(str))\n",
    "        self.df['loop_length'] = (self.df[['end1', 'end2']].max(axis=1) - \n",
    "                                  self.df[['start1', 'start2']].min(axis=1))\n",
    "        ind = ind[(self.df.ix[ind, ['start1', 'start2']].max(axis=1) >\n",
    "                   self.df.ix[ind, ['end1', 'end2']].min(axis=1))]\n",
    "        self.df['loop_inner'] = np.nan\n",
    "        self.df.ix[ind, 'loop_inner'] = (\n",
    "            self.df.ix[ind, 'chrom1'] + ':' + \n",
    "            self.df.ix[ind, ['end1', 'end2']].min(axis=1).astype(str) + '-' +\n",
    "            self.df.ix[ind, ['start1', 'start2']].max(axis=1).astype(str))\n",
    "        self.df['loop_inner_length'] = (\n",
    "            self.df[['start1', 'start2']].max(axis=1) - \n",
    "            self.df[['end1', 'end2']].min(axis=1))\n",
    "        \n",
    "    def bts_from_df(self):         \n",
    "        import pybedtools as pbt\n",
    "        s = '\\n'.join(list(set(\n",
    "            self.df.chrom1.astype(str) + '\\t' + self.df.start1.astype(str) +\n",
    "            '\\t' + self.df.end1.astype(str) + '\\t' + self.df.chrom1.astype(str) + \n",
    "            ':' + self.df.start1.astype(str) + '-' + self.df.end1.astype(str)))) + '\\n'\n",
    "        self.bt1 = pbt.BedTool(s, from_string=True).sort()\n",
    "        s = '\\n'.join(list(set(\n",
    "            self.df.chrom2.astype(str) + '\\t' + self.df.start2.astype(str) +\n",
    "            '\\t' + self.df.end2.astype(str) + '\\t' + self.df.chrom2.astype(str) + \n",
    "            ':' + self.df.start2.astype(str) + '-' + self.df.end2.astype(str)))) + '\\n'\n",
    "        self.bt2 = pbt.BedTool(s, from_string=True).sort()\n",
    "        ind = self.df[self.df.intra].index\n",
    "        s = '\\n'.join(\n",
    "            self.df.ix[ind, 'chrom1'].astype(str) + '\\t' + \n",
    "            self.df.ix[ind, ['start1', 'start2']].min(axis=1).astype(str) + \n",
    "            '\\t' + self.df.ix[ind, ['end1', 'end2']].max(axis=1).astype(str) +\n",
    "            '\\t' + self.df.ix[ind, 'name']) + '\\n'\n",
    "        self.bt_loop = pbt.BedTool(s, from_string=True).sort()\n",
    "        ind = ind[(self.df.ix[ind, ['start1', 'start2']].max(axis=1) >\n",
    "                   self.df.ix[ind, ['end1', 'end2']].min(axis=1))]\n",
    "        s = '\\n'.join(\n",
    "            self.df.ix[ind, 'chrom1'].astype(str) + '\\t' + \n",
    "            self.df.ix[ind, ['end1', 'end2']].min(axis=1).astype(str) + '\\t' +\n",
    "            self.df.ix[ind, ['start1', 'start2']].max(axis=1).astype(str)  +\n",
    "            '\\t' + self.df.ix[ind, 'name']) + '\\n'\n",
    "        self.bt_loop_inner = pbt.BedTool(s, from_string=True).sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GM12878_RNAPII\n",
    "# http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM1872887\n",
    "url = ('http://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM1872887&format=file&file='\n",
    "       'GSM1872887%5FGM12878%5FRNAPII%5FPET%5Fclusters%2Etxt%2Egz')\n",
    "gm_rnap = parse_tang(url)\n",
    "gm_rnap_a = cpb.bedtools.AnnotatedInteractions(gm_rnap, annot_beds, completely_contains=['gene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GM12878_CTCF\n",
    "# http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM1872886\n",
    "url = ('http://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM1872886&format=file&file='\n",
    "       'GSM1872886%5FGM12878%5FCTCF%5FPET%5Fclusters%2Etxt%2Egz')\n",
    "gm_ctcf = parse_tang(url)\n",
    "gm_ctcf_a = cpb.bedtools.AnnotatedInteractions(gm_ctcf, annot_beds, completely_contains=['gene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HeLa_CTCF\n",
    "# http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM1872888\n",
    "url = ('http://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM1872888&format=file&file='\n",
    "       'GSM1872888%5FHeLa%5FCTCF%5FPET%5Fclusters%2Etxt%2Egz')\n",
    "hela_ctcf = parse_tang(url)\n",
    "hela_ctcf_a = cpb.bedtools.AnnotatedInteractions(hela_ctcf, annot_beds, completely_contains=['gene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HeLa_RNAPII\n",
    "# http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM1872889\n",
    "url = ('http://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM1872889&format=file&file='\n",
    "       'GSM1872889%5FHeLa%5FRNAPII%5FPET%5Fclusters%2Etxt%2Egz')\n",
    "hela_rnap = parse_tang(url)\n",
    "hela_rnap_a = cpb.bedtools.AnnotatedInteractions(hela_rnap, annot_beds, completely_contains=['gene'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
