{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eQTL Processing\n",
    "\n",
    "This notebook contains code to read the results from \"Run eQTL Analysis\"\n",
    "and parse them into useful formats. There is a cell or cells in this notebook\n",
    "for each eQTL Analysis often followed by something like `2 +`. This prevents\n",
    "the notebook from being executed all at once. Basically, after running the first\n",
    "few cells to set things up, you probably just want to execute the other cells\n",
    "individually as you need to. \n",
    "\n",
    "Some cells can be executed while the eQTL is running. \n",
    "This allows you to see how many significant hits you are getting etc. as things\n",
    "are running. This code (specifically `process_eqtl_results` \n",
    "is designed to run efficiently by skipping genes that were already\n",
    "parsed and using the already calculated results. However, if some genes' results have\n",
    "changed, you should delete the processing directory (`os.path.join(outdir, 'eqtls01')`\n",
    "for instance) and let `process_eqtl_results` re-process all of the data. This is also\n",
    "sometimes necessary of `process_eqtl_results` hits an error. Often deleting the processing\n",
    "output directory and re-running `process_eqtl_results` will fix the problem.\n",
    "\n",
    "TODO: Add some descriptions below of each eQTL analysis and when the cells should be\n",
    "run (during or after eQTL analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "random.seed(20151226)\n",
    "import subprocess\n",
    "\n",
    "import cdpybio as cpb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import pybedtools as pbt\n",
    "import seaborn as sns\n",
    "import statsmodels.stats.multitest as smm\n",
    "import vcf as pyvcf\n",
    "\n",
    "import cardipspy as cpy\n",
    "import ciepy\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "dy_name = 'eqtl_processing'\n",
    "\n",
    "import socket\n",
    "if socket.gethostname() == 'fl-hn1' or socket.gethostname() == 'fl-hn2':\n",
    "    dy = os.path.join(ciepy.root, 'sandbox', 'tmp', dy_name)\n",
    "    cpy.makedir(dy)\n",
    "    pbt.set_tempdir(dy)\n",
    "    \n",
    "outdir = os.path.join(ciepy.root, 'output', dy_name)\n",
    "cpy.makedir(outdir)\n",
    "\n",
    "private_outdir = os.path.join(ciepy.root, 'private_output', dy_name)\n",
    "cpy.makedir(private_outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transcript_to_gene = pd.read_table(cpy.gencode_transcript_gene, header=None, \n",
    "                                   squeeze=True, index_col=0)\n",
    "gene_info = pd.read_table(cpy.gencode_gene_info, index_col=0)\n",
    "\n",
    "exp = pd.read_table(os.path.join(\n",
    "        ciepy.root, 'output', 'eqtl_input', \n",
    "        'tpm_log_filtered_phe_std_norm_peer_resid.tsv'), \n",
    "                    index_col=0)\n",
    "\n",
    "snpsnap = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "Given a set of eQTL results, I want to create several files:\n",
    "\n",
    "* `lead_variants.tsv` - This file will include the lead variants for each gene including\n",
    "variants that equally significant.\n",
    "* `lead_variants_single.tsv` - This file will include a single lead variant for each gene. I'll\n",
    "choose the most significant randomly if there are ties.\n",
    "* `lead_variants_single_snv.tsv` - This file will include the most significant SNV per gene. If there\n",
    "are ties I'll choose randomly.\n",
    "* `pvalues.tsv` - This file has the permutation p-value for each gene.\n",
    "* `qvalues.tsv` - This file has the permutation p-value, the q-value, and whether the gene is significant.\n",
    "* `sig_snv_independent.tsv` - This file will be created by LD pruning the variants in `most_sig_single_snv.tsv`.\n",
    "* `all_snv_results_sorted.tsv.gz` - This file has the results for all SNVs in all genes. \n",
    "It will be sorted by position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_permutation_pvalues(eqtl_dy, out_dy):\n",
    "    \"\"\"\n",
    "    Calculate empirical p-values based on the p-values from permutations. This function\n",
    "    is pretty slow but it will read the existing output file (if it exists) and not recalculate\n",
    "    p-values for genes that are already done so if you run this repeatedly as the eQTL analysis\n",
    "    is running, it won't take too long at the end.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    eqtl_dy : str\n",
    "        Path to directory with eQTL results. This directory should contain one \n",
    "        subdirectory for each gene tested. Each subdirectory should be named with\n",
    "        the gene ID and contain the files [gene ID].tsv and minimum_pvalues.tsv.\n",
    "        [gene ID].tsv is the EMMAX output for the \"real\" data and minimum_pvalues.tsv\n",
    "        contains the minimum EMMAX p-value for each permutation.\n",
    "        \n",
    "    out_dy : str\n",
    "        Path to directory to write output file pvalues.tsv. This file has \n",
    "        gene IDs in the first column and permutation p-values in the second column.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pvals : pandas.Series\n",
    "        Series with gene IDs as index and permutation p-values as values.\n",
    "        \n",
    "    new_lead_vars : pandas.DataFrame\n",
    "        Dataframe with lead variants for each gene that we've just calculated\n",
    "        permutation p-values for. Note that this is not all genes, just those \n",
    "    \n",
    "    \"\"\"\n",
    "    cpy.makedir(out_dy)\n",
    "    min_fns = glob.glob(os.path.join(eqtl_dy, '*', 'minimum_pvalues.tsv'))\n",
    "    min_fns = pd.Series(min_fns, index=[fn.split(os.path.sep)[-2] for fn in min_fns])\n",
    "    fn = os.path.join(out_dy, 'pvalues.tsv')\n",
    "    if os.path.exists(fn):\n",
    "        pvals = pd.read_table(fn, index_col=0,\n",
    "                              header=None, squeeze=True)\n",
    "    else:\n",
    "        pvals = pd.Series()\n",
    "    new_pvals = []\n",
    "    new_genes = []\n",
    "    new_lead_vars = []\n",
    "\n",
    "    min_fns = min_fns[set(min_fns.index) - set(pvals.index)]\n",
    "    if min_fns.shape[0] > 0:\n",
    "        for fn in min_fns.values:\n",
    "            gene_id = fn.split(os.path.sep)[-2]\n",
    "            new_genes.append(gene_id)\n",
    "            res_fn = os.path.join(os.path.split(fn)[0], '{}.tsv'.format(gene_id))\n",
    "            with open(res_fn) as f:\n",
    "                if len(f.readlines()) == 0:\n",
    "                    print(res_fn)\n",
    "            res = ciepy.read_emmax_output(res_fn)\n",
    "            min_pvals = pd.read_table(fn, header=None, squeeze=True)\n",
    "            p = (1 + sum(min_pvals <= res.PVALUE.min())) / float(min_pvals.shape[0] + 1)\n",
    "            new_pvals.append(p)\n",
    "            t = res[res.PVALUE == res.PVALUE.min()]\n",
    "            t['gene_id'] = gene_id\n",
    "            new_lead_vars.append(t)\n",
    "        new_pvals = pd.Series(new_pvals, index=new_genes)\n",
    "        pvals = pd.concat([pvals, new_pvals])\n",
    "        new_lead_vars = pd.concat(new_lead_vars)\n",
    "        new_lead_vars = parse_emmax_results(new_lead_vars)\n",
    "        return pvals, new_lead_vars\n",
    "    else:\n",
    "        return pvals, None\n",
    "    \n",
    "def parse_emmax_results(df, add_af=True):\n",
    "    \"\"\"\n",
    "    Take a dataframe of results from EMMAX and parse into a more useful format.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Pandas dataframe of EMMAX results read with ciepy.read_emmax_output(). Extra\n",
    "        columns can be present but they may be overwritten. The dataframe must also\n",
    "        include a \"gene_id\" column with the gene ID.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    out : pandas.DataFrame\n",
    "        Parsed version of input df including (1) more reasonable column names, (2) chr\n",
    "        chromosomes, (3) variant type column, \n",
    "    \n",
    "    \"\"\"\n",
    "    # Lowercase column names.\n",
    "    df.columns = [x.lower() for x in df.columns]\n",
    "    # chr chromosome names.\n",
    "    df['chrom'] = 'chr' + df.chrom.astype(int).astype(str)\n",
    "    # Make cooordinates zero-based, half-open (like a bed file).\n",
    "    df['beg'] -= 1\n",
    "    df.columns = ['chrom', 'start'] + list(df.columns[2:])\n",
    "    df.start = df.start.astype(int)\n",
    "    # Add ref/alt alleles. CNVs will just have N for both ref and alt.\n",
    "    df['ref'] = df.marker_id.apply(lambda x: x.split('_')[1].split('/')[0])\n",
    "    df['alt'] = df.marker_id.apply(lambda x: x.split('_')[1].split('/')[1])\n",
    "    # Variant type\n",
    "    df['variant_type'] = 'snv'\n",
    "    df.ix[df.ref.apply(lambda x: len(x)) > df.alt.apply(lambda x: len(x)), 'variant_type'] = 'del'\n",
    "    df.ix[df.ref.apply(lambda x: len(x)) < df.alt.apply(lambda x: len(x)), 'variant_type'] = 'ins'\n",
    "    df.ix[df.marker_id.apply(lambda x: 'CNV' in x), 'variant_type'] = 'cnv'\n",
    "    df.ix[df.marker_id.apply(lambda x: 'DUP' in x), 'variant_type'] = 'cnv'\n",
    "    df.ix[df.marker_id.apply(lambda x: 'DEL' in x), 'variant_type'] = 'cnv'\n",
    "    # Annotate with variant caller\n",
    "    df['variant_caller'] = 'gatk'\n",
    "    df.ix[df.variant_type == 'cnv', 'variant_caller'] = 'genomestrip'\n",
    "    df.ix[df.marker_id.apply(lambda x: 'DUP' in x), 'variant_caller'] = 'lumpy'\n",
    "    df.ix[df.marker_id.apply(lambda x: 'DEL' in x), 'variant_caller'] = 'lumpy'\n",
    "    # CNVs don't have the correct end because I didn't encode that info in the VCF so I'll\n",
    "    # fix that here.\n",
    "    cnv_ends = df.ix[df.variant_type == 'cnv', 'marker_id'].apply(lambda x: int(x.split('_')[-1]))\n",
    "    df.ix[df.variant_type == 'cnv', 'end'] = cnv_ends.values\n",
    "    df.end = df.end.astype(int)\n",
    "    # Add location column.\n",
    "    df['location'] = (df.chrom + ':' + df.start.astype(str) + '-' + df.end.astype(str))\n",
    "    # Create unique index.\n",
    "    df.index = df.location + ':' + df.gene_id\n",
    "    # Add RSIDs. Not all variants have RSIDs.\n",
    "    t = df.marker_id.apply(lambda x: x.split('_')[-1][0:2])\n",
    "    t = t[t == 'rs']\n",
    "    rsids = df.ix[t.index, 'marker_id'].apply(lambda x: x.split('_')[-1])\n",
    "    df.ix[t.index, 'rsid'] = rsids\n",
    "    # Add lengths of variants. I'll calculate lengths separately for different types of variants.\n",
    "    # I won't give SNVs a length.\n",
    "    df['length'] = np.nan\n",
    "    t = df[df.variant_type == 'ins']\n",
    "    df.ix[t.index, 'length'] = t.alt.apply(lambda x: len(x)) - t.ref.apply(lambda x: len(x))\n",
    "    t = df[df.variant_type == 'del']\n",
    "    df.ix[t.index, 'length'] = t.ref.apply(lambda x: len(x)) - t.alt.apply(lambda x: len(x))\n",
    "    t = df[df.variant_type == 'cnv']\n",
    "    df.ix[t.index, 'length'] = t.end - t.start\n",
    "    # Distance to TSS.\n",
    "    df = tss_to_eqtl_gene(df)\n",
    "    # Add some info about the gene.\n",
    "    df = df.merge(gene_info[['gene_name', 'gene_type']], left_on='gene_id', right_index=True)\n",
    "    if add_af:\n",
    "        # Add 1KGP allele frequencies for SNVs.\n",
    "        afs = ['AF', 'EUR_AF', 'SAS_AF', 'AFR_AF', 'AMR_AF', 'EAS_AF']\n",
    "        for af in afs:\n",
    "            df[af] = np.nan\n",
    "        fn = ('/publicdata/1KGP_20151103/ALL.wgs.phase3_shapeit2_mvncall_integrated_v5b.'\n",
    "              '20130502.sites.vcf.gz')\n",
    "        kgp_vcf_reader = pyvcf.Reader(open(fn))\n",
    "        for i in df[df.variant_type == 'snv'].index:\n",
    "            kgp = None\n",
    "            res = kgp_vcf_reader.fetch(df.ix[i, 'chrom'][3:], \n",
    "                                       df.ix[i, 'start'] + 1, \n",
    "                                       df.ix[i, 'start'] + 1)\n",
    "            while True:\n",
    "                try:\n",
    "                    kgp = res.next()\n",
    "                    if kgp.INFO['VT'] == ['SNP']:\n",
    "                        break\n",
    "                except StopIteration:\n",
    "                    break\n",
    "            if kgp:\n",
    "                for af in afs:\n",
    "                    df.ix[i, af] = kgp.INFO[af][0]\n",
    "            else:\n",
    "                for af in afs:\n",
    "                    df.ix[i, af] = 0\n",
    "    return df\n",
    "    \n",
    "def tss_to_eqtl_gene(df):\n",
    "    \"\"\"\n",
    "    Take a dataframe of lead variants and add the distance from the variants\n",
    "    to the nearest TSS for the eQTL gene.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Dataframe with lead variants.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    out : pandas.DataFrame\n",
    "        Dataframe with lead variants with distance to TSS added.\n",
    "    \n",
    "    \"\"\"\n",
    "    tss = pbt.BedTool(cpy.gencode_tss_bed)\n",
    "    tss_df = tss.to_dataframe()\n",
    "    tss_df['gene'] = tss_df.name.apply(lambda x: transcript_to_gene[x.split('_')[0]])\n",
    "    s = '\\n'.join(tss_df.gene + '\\t' + tss_df.start.astype(str) + '\\t' +\n",
    "                  tss_df.end.astype(str) + '\\t' + tss_df.name + '\\t' + \n",
    "                  tss_df.score + '\\t' + tss_df.strand) + '\\n'\n",
    "    fake_tss = pbt.BedTool(s, from_string=True)\n",
    "    fake_tss = fake_tss.sort()\n",
    "\n",
    "    s = '\\n'.join(df.gene_id + '\\t' + df.start.astype(str) + '\\t' + \n",
    "                  df.end.astype(str) + '\\t.\\t' + df.chrom) + '\\n'\n",
    "    fake_df_bt = pbt.BedTool(s, from_string=True)\n",
    "    fake_df_bt = fake_df_bt.sort()\n",
    "\n",
    "    res = fake_df_bt.closest(fake_tss, D='b', sorted=True)\n",
    "    res_df = res.to_dataframe()\n",
    "    res_df.index = (res_df.score + ':' + res_df.start.astype(str) + '-' + \n",
    "                    res_df.end.astype(str) + ':' + res_df.chrom)\n",
    "\n",
    "    res_df['variant_gene'] = res_df.index\n",
    "    res_df = res_df.drop_duplicates(subset=['variant_gene'])\n",
    "\n",
    "    df['tss_dist'] = res_df.ix[df.index, 'blockStarts']\n",
    "    df['tss_dist_abs'] = df.tss_dist.abs()\n",
    "    return df\n",
    "\n",
    "def qvalue(pvals, summary=True, plot=False):\n",
    "    \"\"\"Use the R qvalue package to adjust pvalues. pvals should be a pandas\n",
    "    Series with gene names as the index and pvalues as the values.\"\"\"\n",
    "    import rpy2.robjects as ro\n",
    "    ro.r('suppressMessages(library(qvalue))')\n",
    "    ro.globalenv['pvals'] = pvals\n",
    "    ro.r('qobj = qvalue(p=pvals, fdr.level=0.05)')\n",
    "    ro.r('qvalues <- qobj$qvalues')\n",
    "    ro.r('pi0 <- qobj$pi0')\n",
    "    ro.r('lfdr <- qobj$lfdr')\n",
    "    ro.r('sig <- qobj$significant')\n",
    "    qvalues = ro.globalenv['qvalues']\n",
    "    pi0 = ro.globalenv['pi0']\n",
    "    lfdr = ro.globalenv['lfdr']\n",
    "    sig = ro.globalenv['sig']\n",
    "    qvalue_res = pd.DataFrame([list(pvals), list(qvalues), list(sig)], \n",
    "                              index=['perm_pvalue', 'perm_qvalue', 'perm_sig'],\n",
    "                              columns=pvals.index).T\n",
    "    qvalue_res['perm_sig'] = qvalue_res.perm_sig.astype(bool)\n",
    "    qvalue_res = qvalue_res.sort_values(['perm_qvalue'])\n",
    "    qvalues = pd.Series(list(qvalues), index=pvals.index)\n",
    "    qvalue_res.index.name = None\n",
    "    if summary:\n",
    "        ro.r('summary(qobj)')\n",
    "    if plot:\n",
    "        ro.r('plot(qobj)')\n",
    "    return qvalue_res\n",
    "\n",
    "def make_single_lead_variant(df):\n",
    "    \"\"\"\n",
    "    Take a dataframe of variants and randomly choose one single lead variant\n",
    "    per gene if there are ties.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Dataframe with results from EMMAX.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    out : pandas.DataFrame\n",
    "        Dataframe with a single lead variant per gene.\n",
    "    \n",
    "    \"\"\"\n",
    "    # To choose randomly, I'll assign a random number to each row, then sort\n",
    "    # by gene and row.\n",
    "    random.seed(204050)\n",
    "    out = df.copy(deep=True)\n",
    "    out['random'] = [random.random() for x in out.index]\n",
    "    # Because I sort by pvalue in the next line, the input data frame\n",
    "    # can contain non-lead variants. The row at the top of each gene's\n",
    "    # results will have the minimum p-value.\n",
    "    out = out.sort_values(by=['gene_id', 'pvalue', 'random'])\n",
    "    out = out.drop_duplicates(subset=['gene_id'])\n",
    "    out = out.drop(['random'], axis=1)\n",
    "    return out\n",
    "\n",
    "def process_eqtl_results(eqtl_dy, out_dy):\n",
    "    \"\"\"\n",
    "    This method parses and annotates results from EMMAX, calculates the permutation p-values,\n",
    "    and performs multiple-testing correction. Some of the steps are slow, but\n",
    "    the method will read output files already available in out_dy and not re-analyze genes\n",
    "    that are already present in the output file, so that means you can run this method repeatedly\n",
    "    as the eQTL analysis proceeds. If you want all results reanalyzed, delete the output files \n",
    "    in out_dy before running.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    eqtl_dy : str\n",
    "        Path to directory with eQTL results. This directory should contain one \n",
    "        subdirectory for each gene tested. Each subdirectory should be named with\n",
    "        the gene ID and contain the files [gene ID].tsv and minimum_pvalues.tsv.\n",
    "        [gene ID].tsv is the EMMAX output for the \"real\" data and minimum_pvalues.tsv\n",
    "        contains the minimum EMMAX p-value for each permutation.\n",
    "        \n",
    "    out_dy : str\n",
    "        Path to directory to write output files. The output files are (1) pvalues.tsv:\n",
    "        gene IDs in the first column and permutation p-values in the second column, (2)\n",
    "        qvalues.tsv: results from multiple hypothesis testing, (3) lead_variants.tsv:\n",
    "        the most significant variants per gene, (4) lead_variants_single.tsv: one most\n",
    "        significant variant per gene (ties broken randomly).\n",
    "    \n",
    "    \"\"\"\n",
    "    # Calculate permutation p-values and find lead variants for new genes.\n",
    "    pvals, new_lead_vars = calculate_permutation_pvalues(eqtl_dy, out_dy)\n",
    "    pvals.to_csv(os.path.join(out_dy, 'pvalues.tsv'), sep='\\t')\n",
    "    # Merge new lead variants with lead variants we already calculated if\n",
    "    # they exist.\n",
    "    fn = os.path.join(out_dy, 'lead_variants.tsv')\n",
    "    if os.path.exists(fn):\n",
    "        lead_vars = pd.read_table(fn, index_col=0)\n",
    "    else:\n",
    "        lead_vars = None\n",
    "    if new_lead_vars is not None and lead_vars is not None:\n",
    "        lead_vars = pd.concat([lead_vars, new_lead_vars])\n",
    "    elif new_lead_vars is not None:\n",
    "        lead_vars = new_lead_vars\n",
    "    # Correct for multiple testing.\n",
    "    qvalue_res = qvalue(pvals)\n",
    "    qvalue_res.to_csv(os.path.join(out_dy, 'qvalues.tsv'), sep='\\t')\n",
    "    lead_vars = lead_vars.merge(qvalue_res, left_on='gene_id', right_index=True)\n",
    "    lead_vars.sort_values(by=['gene_id', 'pvalue'], inplace=True)\n",
    "    lead_vars.to_csv(os.path.join(out_dy, 'lead_variants.tsv'), sep='\\t')\n",
    "    # Make dataframe with single lead variant per gene.\n",
    "    lead_vars_single = make_single_lead_variant(lead_vars)\n",
    "    lead_vars_single.to_csv(os.path.join(out_dy, 'lead_variants_single.tsv'), sep='\\t')\n",
    "\n",
    "def make_gene_variant_pairs(qvalue_res, eqtl_dy):\n",
    "    \"\"\"\n",
    "    Make a dataframe with all significant variants per gene. \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    qvalue_res : pandas.DataFrame\n",
    "        Dataframe with columns perm_pvalue, perm_qvalue, and perm_sig. This is the \n",
    "        output from the qvalue() method.\n",
    "        \n",
    "    eqtl_dy : str\n",
    "        Path to directory with eQTL results. This directory should contain one \n",
    "        subdirectory for each gene tested. Each subdirectory should be named with\n",
    "        the gene ID and contain the files [gene ID].tsv and minimum_pvalues.tsv.\n",
    "        [gene ID].tsv is the EMMAX output for the \"real\" data and minimum_pvalues.tsv\n",
    "        contains the minimum EMMAX p-value for each permutation.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    gene_variant_pairs : pandas.DataFrame\n",
    "        Dataframe with all significant gene-variant pairs.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Get permutation p-value cutoff that maps to q = 0.05. I'll do this by finding\n",
    "    # the largest permutation p-value that is still significant.\n",
    "    # It's necessary to round this p-value because the floating point numbers get \n",
    "    # a little messed up. I found that some significant p-values weren't included\n",
    "    # because the max permutation p-value was slightly smaller than it should be\n",
    "    # due to floating point errors.\n",
    "    qvalue_res = qvalue_res[qvalue_res.perm_sig]\n",
    "    gene_variant_pairs = []\n",
    "    for gene_id in qvalue_res.index:\n",
    "        gene_variant_pairs.append(get_all_significant_variants(gene_id, eqtl_dy))\n",
    "    gene_variant_pairs = pd.concat(gene_variant_pairs)\n",
    "    gene_variant_pairs = parse_emmax_results(gene_variant_pairs, add_af=False)\n",
    "    gene_variant_pairs.sort_values(by=['gene_id', 'pvalue'], inplace=True)\n",
    "    return gene_variant_pairs\n",
    "\n",
    "def get_all_significant_variants(gene_id, eqtl_dy):\n",
    "    \"\"\"\n",
    "    Calculate permutation p-values for all variants tested for a given gene gene_id\n",
    "    and return a dataframe with variants whose permutation p-value is less than\n",
    "    perm_pval.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gene_id : str\n",
    "        Gene ID to calculate permutation p-values for.\n",
    "        \n",
    "    eqtl_dy : str\n",
    "        Path to directory with eQTL results. This directory should contain one \n",
    "        subdirectory for each gene tested. Each subdirectory should be named with\n",
    "        the gene ID and contain the files [gene ID].tsv and minimum_pvalues.tsv.\n",
    "        [gene ID].tsv is the EMMAX output for the \"real\" data and minimum_pvalues.tsv\n",
    "        contains the minimum EMMAX p-value for each permutation.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    res : pandas.DataFrame\n",
    "        Dataframe with all significant variants for this gene.\n",
    "    \n",
    "    \"\"\"\n",
    "    fn = os.path.join(eqtl_dy, gene_id, 'minimum_pvalues.tsv')\n",
    "    min_pvals = pd.read_table(fn, header=None, names=['pvalue'])\n",
    "    res_fn = os.path.join(os.path.split(fn)[0], '{}.tsv'.format(gene_id))\n",
    "    res = ciepy.read_emmax_output(res_fn).dropna(subset=['PVALUE'])\n",
    "    min_pvals['null'] = True\n",
    "    df = pd.DataFrame({'pvalue':res.PVALUE, 'null':False}).drop_duplicates().dropna()\n",
    "    t = pd.concat([df, min_pvals])\n",
    "    t.sort_values(by=['pvalue'], inplace=True)\n",
    "    t['num_null'] = t.null.cumsum()\n",
    "    t['perm_pval'] = (t.num_null + 1) / t.null.sum()\n",
    "    t = t[t.null == False]\n",
    "    t = t.drop(['null', 'num_null'], axis=1)\n",
    "    res = res.merge(t, left_on='PVALUE', right_on='pvalue').drop('pvalue', axis=1)\n",
    "    res = res[res.perm_pval == res.perm_pval.min()]\n",
    "    res['gene_id'] = gene_id\n",
    "    return res\n",
    "\n",
    "def post_process_eqtl_results(eqtl_dy, out_dy):\n",
    "    \"\"\"\n",
    "    This method creates several more output files. Unlike process_eqtl_results, it's better\n",
    "    to wait and run this method after the eQTLs are all done.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    eqtl_dy : str\n",
    "        Path to directory with eQTL results. This directory should contain one \n",
    "        subdirectory for each gene tested. Each subdirectory should be named with\n",
    "        the gene ID and contain the files [gene ID].tsv and minimum_pvalues.tsv.\n",
    "        [gene ID].tsv is the EMMAX output for the \"real\" data and minimum_pvalues.tsv\n",
    "        contains the minimum EMMAX p-value for each permutation.\n",
    "        \n",
    "    out_dy : str\n",
    "        Path to directory to write output files. The output files are TODO\n",
    "    \n",
    "    \"\"\"\n",
    "    qvalue_res = pd.read_table(os.path.join(out_dy, 'qvalues.tsv'), index_col=0)\n",
    "    # Make file with all significant gene-variant pairs.\n",
    "    gvp = make_gene_variant_pairs(qvalue_res, eqtl_dy)\n",
    "    gvp.to_csv(os.path.join(out_dy, 'gene_variant_pairs.tsv'), sep='\\t')\n",
    "    # Make file with lead SNV for each significant gene (if there is a significant\n",
    "    # SNV for the gene). Note this only has genes that were significant.\n",
    "    sig_lead_snvs = make_single_lead_variant(gvp[gvp.variant_type == 'snv'])\n",
    "    sig_lead_snvs.to_csv(os.path.join(out_dy, 'sig_lead_snvs_single.tsv'), sep='\\t')\n",
    "    # LD prune lead SNVs.\n",
    "    indep = get_independent_snvs(sig_lead_snvs)\n",
    "    indep.to_csv(os.path.join(out_dy, 'independent_lead_snvs.tsv'), sep='\\t')\n",
    "    s = '\\n'.join(indep[['chrom', 'start', 'end']].apply(\n",
    "            lambda x: '\\t'.join([str(y) for y in x.values]), axis=1)) + '\\n'\n",
    "    bt = pbt.BedTool(s, from_string=True)\n",
    "    bt = bt.sort()\n",
    "    bt.saveas(os.path.join(out_dy, 'independent_lead_snvs.bed'))\n",
    "    # Make pseudoheritability file.\n",
    "    fns = glob.glob(os.path.join(eqtl_dy, '*', 'ENS*.reml'))\n",
    "    h2 = []\n",
    "    for fn in fns:\n",
    "        with open(fn) as f:\n",
    "            h2.append(f.readlines()[-1].split()[1])\n",
    "    h2 = pd.Series(h2, index=[x.split('/')[-2] for x in fns])\n",
    "    h2 = h2.astype(float)\n",
    "    h2.to_csv(os.path.join(out_dy, 'h2.tsv'), sep='\\t')\n",
    "\n",
    "def get_snpsnap():\n",
    "    snpsnap_fns = glob.glob('/publicdata/SNPsnap_20151104/EUR_parse/*.tab')\n",
    "    dfs = []\n",
    "    for tab in snpsnap_fns:\n",
    "        df = pd.read_table(tab, index_col=0, low_memory=False)\n",
    "        tdf = df[['snp_maf', 'dist_nearest_gene_snpsnap_protein_coding',\n",
    "                  'friends_ld08']]\n",
    "        tdf.index = 'chr' + tdf.index\n",
    "        dfs.append(tdf)\n",
    "    snps = pd.concat(dfs)\n",
    "    snps['maf_bin'] = pd.cut(snps.snp_maf, np.arange(0, 0.55, 0.05))\n",
    "    snps['ld_bin'] = pd.cut(np.log10(snps.friends_ld08.replace(np.nan, 0) + 1), 10)\n",
    "    snps['dist_bin'] = pd.cut(np.log10(snps.dist_nearest_gene_snpsnap_protein_coding\n",
    "                                       + 1), 10)\n",
    "    snps = snps[['maf_bin', 'ld_bin', 'dist_bin']]\n",
    "    return snps\n",
    "\n",
    "def get_independent_snvs(df):\n",
    "    ld_beds = glob.glob('/publicdata/1KGP_20151103/LD/tabix/*EUR*.bed.gz')\n",
    "    ld_beds = dict(zip([os.path.split(x)[1].split('_')[0] for x in ld_beds], ld_beds))\n",
    "    df = df.drop_duplicates(subset=['location'])\n",
    "    tdf = df[['chrom', 'start', 'end', 'pvalue']]\n",
    "    tdf.index = tdf.chrom + ':' + tdf.end.astype(str)\n",
    "    indep = cpb.analysis.ld_prune(tdf, ld_beds, snvs=list(snpsnap.index)).drop('pvalue', axis=1)\n",
    "    return indep\n",
    "\n",
    "def pseudo(eqtl_dy, out_dy):\n",
    "    cpy.makedir(out_dy)\n",
    "    fns = glob.glob(os.path.join(eqtl_dy, '*', 'ENS*.reml'))\n",
    "    h2 = []\n",
    "    for fn in fns:\n",
    "        with open(fn) as f:\n",
    "            h2.append(f.readlines()[-1].split()[1])\n",
    "    h2 = pd.Series(h2, index=[x.split('/')[-2] for x in fns])\n",
    "    h2 = h2.astype(float)\n",
    "    h2.to_csv(os.path.join(out_dy, 'h2.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2 +"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing during eQTL run\n",
    "\n",
    "### First eQTLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "qvalue(p = pvals, fdr.level = 0.05)\n",
      "\n",
      "pi0:\t0.3978257\t\n",
      "\n",
      "Cumulative number of significant calls:\n",
      "\n",
      "          <1e-04 <0.001 <0.01 <0.025 <0.05 <0.1    <1\n",
      "p-value     2699   3401  4410   5139  5944 7102 17812\n",
      "q-value        0   3125  4096   4822  5619 7102 17819\n",
      "local FDR      0   2699  3286   3535  3831 4329 17819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eqtl_dy = '/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output/run_eqtl_analysis/eqtls01/gene_results'\n",
    "out_dy = os.path.join(outdir, 'eqtls01')\n",
    "process_eqtl_results(eqtl_dy, out_dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second eQTLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "qvalue(p = pvals, fdr.level = 0.05)\n",
      "\n",
      "pi0:\t0.4705154\t\n",
      "\n",
      "Cumulative number of significant calls:\n",
      "\n",
      "          <1e-04 <0.001 <0.01 <0.025 <0.05 <0.1   <1\n",
      "p-value      222    365   617    873  1135 1590 5618\n",
      "q-value        0      0   387    510   668 1017 5619\n",
      "local FDR      0      0   276    345   404  535 5610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eqtl_dy = '/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output/run_eqtl_analysis/eqtls02/gene_results'\n",
    "out_dy = os.path.join(outdir, 'eqtls02')\n",
    "process_eqtl_results(eqtl_dy, out_dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third eQTLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_table(os.path.join(outdir, 'eqtls02', 'qvalues.tsv'), index_col=0)\n",
    "b = pd.read_table(os.path.join(outdir, 'eqtls03', 'qvalues.tsv'), index_col=0)\n",
    "set(a[a.perm_sig].index) - set(b.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "qvalue(p = pvals, fdr.level = 0.05)\n",
      "\n",
      "pi0:\t0.2078424\t\n",
      "\n",
      "Cumulative number of significant calls:\n",
      "\n",
      "          <1e-04 <0.001 <0.01 <0.025 <0.05 <0.1  <1\n",
      "p-value       30     50   107    141   181  230 668\n",
      "q-value        0     33    90    141   201  362 668\n",
      "local FDR      0      0    50     77   120  177 668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eqtl_dy = '/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output/run_eqtl_analysis/eqtls03/gene_results'\n",
    "out_dy = os.path.join(outdir, 'eqtls03')\n",
    "process_eqtl_results(eqtl_dy, out_dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unrelateds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "qvalue(p = pvals, fdr.level = 0.05)\n",
      "\n",
      "pi0:\t0.601358\t\n",
      "\n",
      "Cumulative number of significant calls:\n",
      "\n",
      "          <1e-04 <0.001 <0.01 <0.025 <0.05 <0.1    <1\n",
      "p-value     1666   2251  3045   3690  4423 5540 17808\n",
      "q-value        0   1666  2478   2863  3310 4107 17819\n",
      "local FDR      0      0  1992   2181  2371 2605 17819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eqtl_dy = ('/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output'\n",
    "           '/run_eqtl_analysis/unrelated_eqtls01/gene_results')\n",
    "out_dy = os.path.join(outdir, 'unrelated_eqtls01')\n",
    "process_eqtl_results(eqtl_dy, out_dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if snpsnap is None:\n",
    "    snpsnap = get_snpsnap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eqtl_dy = ('/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output/'\n",
    "           'run_eqtl_analysis/eqtls01/gene_results/')\n",
    "out_dy = os.path.join(outdir, 'eqtls01')\n",
    "gvp = post_process_eqtl_results(eqtl_dy, out_dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eqtl_dy = ('/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output/'\n",
    "           'run_eqtl_analysis/eqtls02/gene_results/')\n",
    "out_dy = os.path.join(outdir, 'eqtls02')\n",
    "gvp = post_process_eqtl_results(eqtl_dy, out_dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eqtl_dy = ('/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output/'\n",
    "           'run_eqtl_analysis/eqtls03/gene_results')\n",
    "out_dy = os.path.join(outdir, 'eqtls03')\n",
    "post_process_eqtl_results(eqtl_dy, out_dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eqtl_dy = ('/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output'\n",
    "           '/run_eqtl_analysis/unrelated_eqtls01/gene_results')\n",
    "out_dy = os.path.join(outdir, 'unrelated_eqtls01')\n",
    "post_process_eqtl_results(eqtl_dy, out_dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2  +"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No PEER factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eqtl_dy = ('/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output/'\n",
    "           'run_eqtl_analysis/no_peer01/gene_results')\n",
    "out_dy = os.path.join(outdir, 'no_peer01')\n",
    "pseudo(eqtl_dy, out_dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eqtl_dy = ('/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output/'\n",
    "           'run_eqtl_analysis/no_peer_no_std_norm01/gene_results')\n",
    "out_dy = os.path.join(outdir, 'no_peer_no_std_norm01')\n",
    "pseudo(eqtl_dy, out_dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unrelateds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_min_pvals(eqtl_dy, out_dy):\n",
    "    \"\"\"\n",
    "    Find the minimum p-value for each gene.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    eqtl_dy : str\n",
    "        Path to directory with eQTL results. This directory should contain one \n",
    "        subdirectory for each gene tested. Each subdirectory should be named with\n",
    "        the gene ID and contain the files [gene ID].tsv and minimum_pvalues.tsv.\n",
    "        [gene ID].tsv is the EMMAX output for the \"real\" data and minimum_pvalues.tsv\n",
    "        contains the minimum EMMAX p-value for each permutation.\n",
    "        \n",
    "    out_dy : str\n",
    "        Path to directory to write output file pvalues.tsv. This file has \n",
    "        gene IDs in the first column and permutation p-values in the second column.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    min_pvals : pandas.Series\n",
    "        Series with gene IDs as index and permutation p-values as values.\n",
    "        \n",
    "    \"\"\"\n",
    "    cpy.makedir(out_dy)\n",
    "    fn = os.path.join(out_dy, 'min_pvalues.tsv')\n",
    "    genes = []\n",
    "    min_pvals = []\n",
    "\n",
    "    fns = glob.glob(os.path.join(eqtl_dy, '*', 'ENSG*.tsv'))\n",
    "    for fn in fns:\n",
    "        gene_id = fn.split(os.path.sep)[-2]\n",
    "        genes.append(gene_id)\n",
    "        res = ciepy.read_emmax_output(fn)\n",
    "        min_pvals.append(res.PVALUE.min())\n",
    "    min_pvals = pd.Series(min_pvals, index=genes)\n",
    "    min_pvals.to_csv(os.path.join(out_dy, 'min_pvalues.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 40\n",
    "eqtl_dy = ('/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output/'\n",
    "           'run_eqtl_analysis/unrelated_eqtls_{}/gene_results'.format(i))\n",
    "out_dy = os.path.join(outdir, 'unrelated_eqtls_{}'.format(i))\n",
    "\n",
    "fn = os.path.join(out_dy, 'min_pvalues_corrected.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    get_min_pvals(eqtl_dy, out_dy)\n",
    "    pvals = pd.read_table(os.path.join(out_dy, 'min_pvalues.tsv'), \n",
    "                          index_col=0, header=None, names=['min_pval'])\n",
    "    corrected = smm.multipletests(pvals.min_pval, method='bonferroni')\n",
    "    pvals['sig'] = corrected[0]\n",
    "    pvals['min_pval_bf'] = corrected[1]\n",
    "    pvals.to_csv(fn, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 50\n",
    "eqtl_dy = ('/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output/'\n",
    "           'run_eqtl_analysis/unrelated_eqtls_{}/gene_results'.format(i))\n",
    "out_dy = os.path.join(outdir, 'unrelated_eqtls_{}'.format(i))\n",
    "\n",
    "fn = os.path.join(out_dy, 'min_pvalues_corrected.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    get_min_pvals(eqtl_dy, out_dy)\n",
    "    pvals = pd.read_table(os.path.join(out_dy, 'min_pvalues.tsv'), \n",
    "                          index_col=0, header=None, names=['min_pval'])\n",
    "    corrected = smm.multipletests(pvals.min_pval, method='bonferroni')\n",
    "    pvals['sig'] = corrected[0]\n",
    "    pvals['min_pval_bf'] = corrected[1]\n",
    "    pvals.to_csv(fn, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 60\n",
    "eqtl_dy = ('/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output/'\n",
    "           'run_eqtl_analysis/unrelated_eqtls_{}/gene_results'.format(i))\n",
    "out_dy = os.path.join(outdir, 'unrelated_eqtls_{}'.format(i))\n",
    "\n",
    "fn = os.path.join(out_dy, 'min_pvalues_corrected.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    get_min_pvals(eqtl_dy, out_dy)\n",
    "    pvals = pd.read_table(os.path.join(out_dy, 'min_pvalues.tsv'), \n",
    "                          index_col=0, header=None, names=['min_pval'])\n",
    "    corrected = smm.multipletests(pvals.min_pval, method='bonferroni')\n",
    "    pvals['sig'] = corrected[0]\n",
    "    pvals['min_pval_bf'] = corrected[1]\n",
    "    pvals.to_csv(fn, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 70\n",
    "eqtl_dy = ('/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output/'\n",
    "           'run_eqtl_analysis/unrelated_eqtls_{}/gene_results'.format(i))\n",
    "out_dy = os.path.join(outdir, 'unrelated_eqtls_{}'.format(i))\n",
    "\n",
    "fn = os.path.join(out_dy, 'min_pvalues_corrected.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    get_min_pvals(eqtl_dy, out_dy)\n",
    "    pvals = pd.read_table(os.path.join(out_dy, 'min_pvalues.tsv'), \n",
    "                          index_col=0, header=None, names=['min_pval'])\n",
    "    corrected = smm.multipletests(pvals.min_pval, method='bonferroni')\n",
    "    pvals['sig'] = corrected[0]\n",
    "    pvals['min_pval_bf'] = corrected[1]\n",
    "    pvals.to_csv(fn, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 80\n",
    "eqtl_dy = ('/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output/'\n",
    "           'run_eqtl_analysis/unrelated_eqtls_{}/gene_results'.format(i))\n",
    "out_dy = os.path.join(outdir, 'unrelated_eqtls_{}'.format(i))\n",
    "\n",
    "fn = os.path.join(out_dy, 'min_pvalues_corrected.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    get_min_pvals(eqtl_dy, out_dy)\n",
    "    pvals = pd.read_table(os.path.join(out_dy, 'min_pvalues.tsv'), \n",
    "                          index_col=0, header=None, names=['min_pval'])\n",
    "    corrected = smm.multipletests(pvals.min_pval, method='bonferroni')\n",
    "    pvals['sig'] = corrected[0]\n",
    "    pvals['min_pval_bf'] = corrected[1]\n",
    "    pvals.to_csv(fn, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 90\n",
    "eqtl_dy = ('/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output/'\n",
    "           'run_eqtl_analysis/unrelated_eqtls_{}/gene_results'.format(i))\n",
    "out_dy = os.path.join(outdir, 'unrelated_eqtls_{}'.format(i))\n",
    "\n",
    "fn = os.path.join(out_dy, 'min_pvalues_corrected.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    get_min_pvals(eqtl_dy, out_dy)\n",
    "    pvals = pd.read_table(os.path.join(out_dy, 'min_pvalues.tsv'), \n",
    "                          index_col=0, header=None, names=['min_pval'])\n",
    "    corrected = smm.multipletests(pvals.min_pval, method='bonferroni')\n",
    "    pvals['sig'] = corrected[0]\n",
    "    pvals['min_pval_bf'] = corrected[1]\n",
    "    pvals.to_csv(fn, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 100\n",
    "eqtl_dy = ('/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output/'\n",
    "           'run_eqtl_analysis/unrelated_eqtls_{}/gene_results'.format(i))\n",
    "out_dy = os.path.join(outdir, 'unrelated_eqtls_{}'.format(i))\n",
    "\n",
    "fn = os.path.join(out_dy, 'min_pvalues_corrected.tsv')\n",
    "if not os.path.exists(fn):\n",
    "    get_min_pvals(eqtl_dy, out_dy)\n",
    "    pvals = pd.read_table(os.path.join(out_dy, 'min_pvalues.tsv'), \n",
    "                          index_col=0, header=None, names=['min_pval'])\n",
    "    corrected = smm.multipletests(pvals.min_pval, method='bonferroni')\n",
    "    pvals['sig'] = corrected[0]\n",
    "    pvals['min_pval_bf'] = corrected[1]\n",
    "    pvals.to_csv(fn, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2 + "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Results\n",
    "\n",
    "I want to make a file with all EMMAX results combined. I am going to \n",
    "sort this file by position and $p$-value. This will allow me to \n",
    "collect some stats like the smallest $p$-value observed for each SNV,\n",
    "how many times a SNV was tested, etc.\n",
    "\n",
    "I'll use the IPython cluster to sort the individual output files then\n",
    "merge them using `sort -m`. This is much faster than concatenating and\n",
    "sorting though the merging still takes a few hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_combined_results(eqtl_dy, out_dy):\n",
    "    out = os.path.join(out_dy, 'all_snv_results_sorted.tsv.gz')\n",
    "    dy = os.path.join(outdir, 'tmp')\n",
    "    cpy.makedir(dy)\n",
    "    fns = glob.glob(os.path.join(eqtl_dy, 'ENS*', 'ENS*.tsv'))\n",
    "    commands = ['sort -k1,1 -k2,2n -k3,3n -k11,11n {} | grep -v ^# | '\n",
    "                'awk \\'{{print $0\"\\t{}\"}}\\' > {}'.format(x, x.split('/')[-2], os.path.join(dy, os.path.split(x)[1]))\n",
    "                for x in fns]\n",
    "    from ipyparallel import Client\n",
    "    parallel_client = Client(profile='parallel')\n",
    "    dview = parallel_client[:]\n",
    "    print('Cluster has {} engines.'.format(len(parallel_client.ids)))\n",
    "    with dview.sync_imports():\n",
    "        import subprocess\n",
    "    dview.scatter('commands', commands)\n",
    "    %px y = [subprocess.check_call(i, shell=True) for i in commands]\n",
    "    c = 'sort -m -k1,1 -k2,2n -k3,3n -k11,11n {} | bgzip -c > {}'.format(os.path.join(dy, '*'), out)\n",
    "    subprocess.check_call(c, shell=True)\n",
    "    c = 'tabix -p bed {}'.format(out)\n",
    "    subprocess.check_call(c, shell=True)\n",
    "    c = 'rm -r {}'.format(dy)\n",
    "    subprocess.check_call(c, shell=True)\n",
    "    \n",
    "    out2 = os.path.join(out_dy, 'top_snv_results_sorted.tsv.gz')\n",
    "    c = (\"zcat {} | awk 'a!~$1 || b!~$2 || c!~$3 ; {{a=$1}} {{b=$2}} {{c=$3}}' | \"\n",
    "         \"bgzip -c > {}\".format(out, out2))\n",
    "    subprocess.check_call(c, shell=True)\n",
    "    c = 'tabix -p bed {}'.format(out2)\n",
    "    subprocess.check_call(c, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eqtl_dy = '/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output/run_eqtl_analysis/eqtls01/gene_results'\n",
    "out_dy = os.path.join(outdir, 'eqtls01')\n",
    "make_combined_results(eqtl_dy, out_dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in [40, 50, 60, 70, 80, 90, 100]:\n",
    "    eqtl_dy = ('/projects/CARDIPS/analysis/cardips-ipsc-eqtl/private_output/'\n",
    "               'run_eqtl_analysis/unrelated_eqtls_{}/gene_results'.format(i))\n",
    "    out_dy = os.path.join(outdir, 'unrelated_eqtls_{}'.format(i))\n",
    "    make_combined_results(eqtl_dy, out_dy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
